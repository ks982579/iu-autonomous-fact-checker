{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11f1914f",
   "metadata": {},
   "source": [
    "# Exploring data\n",
    "\n",
    "Since the first model trained had some performance issues, we need to better evaluate the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc0478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8897759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- part  0 ---\n",
      "   sentence_id  label                                               text\n",
      "0        27247      1                We're 9 million jobs short of that.\n",
      "1        10766      1  You know, last year up to this time, we've los...\n",
      "2         3327      1  And in November of 1975 I was the first presid...\n",
      "3        19700      1  And what we've done during the Bush administra...\n",
      "4        12600      1  Do you know we don't have a single program spo...\n",
      "        sentence_id        label\n",
      "count   9674.000000  9674.000000\n",
      "mean   16268.353628     0.285714\n",
      "std     9388.575939     0.451777\n",
      "min       16.000000     0.000000\n",
      "25%     8344.000000     0.000000\n",
      "50%    16455.500000     0.000000\n",
      "75%    24086.250000     1.000000\n",
      "max    34458.000000     1.000000\n",
      "--- part  1 ---\n",
      "   sentence_id  label                                               text\n",
      "0        15083      1  When I made my decision to stop all trade with...\n",
      "1        16799      1  We've got the highest inflation we've had in t...\n",
      "2        32570      1  They started from that little area, and now th...\n",
      "3        17644      1  Yes, there has been an increase in poverty, bu...\n",
      "4        32512      1  And, yes, when I was a senator, I did vote to ...\n",
      "        sentence_id        label\n",
      "count   8292.000000  8292.000000\n",
      "mean   16231.974433     0.333333\n",
      "std     9412.544929     0.471433\n",
      "min       20.000000     0.000000\n",
      "25%     8379.500000     0.000000\n",
      "50%    16394.500000     0.000000\n",
      "75%    24028.250000     1.000000\n",
      "max    34458.000000     1.000000\n",
      "--- part  2 ---\n",
      "   sentence_id  label                                               text\n",
      "0         8967      1  In other words, I have seen his program costed...\n",
      "1        27385      1  Our Navy is old -- excuse me, our Navy is smal...\n",
      "2         9818      1  The unemployment, the number of people who are...\n",
      "3        16794      1  Mr. Ford uh - actually has fewer people now in...\n",
      "4        17588      1  Today it is up to about $38,000 of earnings th...\n",
      "        sentence_id         label\n",
      "count  11056.000000  11056.000000\n",
      "mean   16330.066299      0.250000\n",
      "std     9405.549195      0.433032\n",
      "min       16.000000      0.000000\n",
      "25%     8419.750000      0.000000\n",
      "50%    16491.500000      0.000000\n",
      "75%    24134.250000      0.250000\n",
      "max    34457.000000      1.000000\n"
     ]
    }
   ],
   "source": [
    "here = Path().cwd()\n",
    "cbdata_path = here / \".data_sets\" / \"ClaimBuster_Datasets\" / \"datasets\" # ClaimBuster data location\n",
    "raw_dfs: List[pd.DataFrame] = []\n",
    "\n",
    "for file in cbdata_path.iterdir():\n",
    "    if file.exists() and file.is_file() and file.suffix == \".json\":\n",
    "        tmp: pd.DataFrame = pd.read_json(file)\n",
    "        raw_dfs.append(tmp)\n",
    "\n",
    "assert len(raw_dfs) > 0\n",
    "\n",
    "for i, j in enumerate(raw_dfs):\n",
    "    assert j is not None\n",
    "    assert type(j) is pd.DataFrame\n",
    "    print(f\"--- part {i:2} ---\")\n",
    "    print(j.head())\n",
    "    print(j.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9d0845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sentence_id         label\n",
      "count  29022.000000  29022.000000\n",
      "mean   16281.469161      0.285714\n",
      "std     9401.659478      0.451762\n",
      "min       16.000000      0.000000\n",
      "25%     8384.500000      0.000000\n",
      "50%    16455.500000      0.000000\n",
      "75%    24089.000000      1.000000\n",
      "max    34458.000000      1.000000\n",
      "Dataset Size: 29022\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(raw_dfs)\n",
    "print(df.describe())\n",
    "print(f\"Dataset Size: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cdb71f",
   "metadata": {},
   "source": [
    "## Analysis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f09c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CLAIMBUSTERS DATA QUALITY ANALYSIS ===\n",
      "\n",
      "1. LABEL DISTRIBUTION:\n",
      "Total samples: 29022\n",
      "Claims (LABEL_1): 8292 (28.6%)\n",
      "Non-claims (LABEL_0): 20730 (71.4%)\n",
      "\n",
      "2. SUSPICIOUS NON-CLAIM LABELS (should probably be claims):\n",
      "Found 245 suspicious non-claim labels\n",
      "Sample suspicious non-claims:\n",
      " 1. We feel that you can hold the line and restrain federal spending, give a tax reduction and still have a balanced budget by 1978.\n",
      " 2. And for every dollar that I spend in those two categories, I'll put $2 toward paying down the national debt.\n",
      " 3. And in the years to come it will be written that one or the other of us was elected and that he was or was not a great president.\n",
      " 4. In 1957 I was in Havana.\n",
      " 5. I think uh - the way to get tax equity in this country is to give tax relief to the middle-income people who have an income from roughly $8 thousand up to twenty-five or thirty thousand dollars.\n",
      " 6. We've got to innovate through this America 2000 program.\n",
      " 7. George, we have supply management today under the 1985 bill.\n",
      " 8. And doesn't that prove the point, George, which is that values like family and education and community, decent homes for young people that family on Long Island I visited on Monday where Lou and Betty Tolamo (phonetic) bought a house for some $19,000 back in 1962, have had seven children, they're all making good livings.\n",
      " 9. But we also have to develop clean energy technologies that will allow us to cut our exports in half by 2020.\n",
      "10. He says that he's going to give you a $5,000 tax credit.\n",
      "11. In addition to that, jobs programs to re-employ the youth in our cities would be very high on my priority list, both the Youth Opportunities Act of 1980 and a billion-dollar program that I would recommend to put youth to work in energy projects, in conservation projects, in projects that would carry out some of the great national goals of our country.\n",
      "12. I'm going to give them $5,000 to take with them wherever they want to go, and this will give them affordability.\n",
      "13. If somebody came to you, Governor, with a plan that said, here, I want to spend $7 or $8 trillion, and then we're going to pay for it, but we can't tell you until maybe after the election how we're going to do it, you wouldn't take such a sketchy deal and neither should you, the American people, because the math doesn't add up.\n",
      "14. Well, Mr. Nixon, to go back to 1955.\n",
      "15. I want to give every American a $5,000 refundable tax credit.\n",
      "\n",
      "3. SUSPICIOUS CLAIM LABELS (should probably be non-claims):\n",
      "Found 1011 suspicious claim labels\n",
      "Sample suspicious claims:\n",
      " 1. And in November of 1975 I was the first president to order the executive branch to take action, affirmative action, through the Department of Commerce and other cabinet departments, to make certain that no American businessman or business organization should discriminate against Jews because of an Arab boycott.\n",
      " 2. Georgie Anne, we, believe me, supported the Simpson-Mazzoli bill strongly -- and the bill that came out of the Senate.\n",
      " 3. But now I think there have been a couple of instances where the Burger Court has made technical rulings where an obviously guilty person was later found to be guilty.\n",
      " 4. In my opinion, as we deal with this deficit, people from about $70,000 a year on down have to be dealt with very, very carefully, because they are the ones who didn't get any relief the first time around.\n",
      " 5. In terms of programs, I've submitted, what, 4 different budgets to the US Congress in great detail.\n",
      " 6. But I also believe we need an agricultural policy which doesn't cost us 15 to 20 to 25 billion dollars a year that it's been costing us over the course of the past three or four years under this administration.\n",
      " 7. They don't want to see the world break out into -- into various forms of chaos, because they have to -- they have to manufacture goods and put people to work and they have about 20,000 -- 20 million, rather, people coming out of the farms every year coming into the cities, needing jobs.\n",
      " 8. If we assume the ah - uh - a rate of growth of our economy, equivalent to what it was during President Johnson, President Kennedy, even before the - the - the - uh wa uh - Vietnese- namese War, and if we assume that at the end of the four-year period we can cut our unemployment rate down to 4 to 4 and a half percent - under those circumstances, even assuming no elimination of unnecessary programs and assuming an increase in the ad- in the allotment of money to finance programs, increasing as the inflation rate does - my economic projections, I think confirmed by the House uh - and the Senate committees, have been with the $60 billion extra amount of money that can be spent in fiscal year '81 which will be the last year of this next term.\n",
      " 9. I donÃ¢â‚¬â„¢t think he will because under his plan if you work out the numbers Ã‚ $100 billion comes out of Medicare just for the wealthiest 1% in the tax cut.\n",
      "10. This is the worst trade year in American history by far.\n",
      "11. Now, to suggest that because two Republican presidents tried to pass the SALT treaty - that puts them on its side - I would like to say that President Ford, who was within 90% of a treaty that we could be in agreement with when he left office, is emphatically against this SALT treaty.\n",
      "12. In February he said we had the best economy in Ã‚ 30 years, just February.\n",
      "13. We have presided over the largest increase in government since the Great Society.\n",
      "14. I think they're better off, all of us are, that we got the interest rates down and the deficit down.\n",
      "15. When you come to Washington to try to - as a governor - to try to begin a new program for your people, like uh the treatment of drug addicts, I found there were thirteen different federal agencies that I had to go to, to manage the uh drug treatment program.\n",
      "\n",
      "4. SAMPLE LENGTH ANALYSIS:\n",
      "Average text length: 100.0 characters\n",
      "Shortest text: 17 chars\n",
      "Longest text: 833 chars\n",
      "\n",
      "Very short samples (81):\n",
      "  'We used to have 18.' → Label: 1\n",
      "  'I just can't do it.' → Label: 0\n",
      "  'I have a tax cut.' → Label: 0\n",
      "  'He came to see me.' → Label: 0\n",
      "  'We have to be bold.' → Label: 0\n",
      "  'I hope a lot of --' → Label: 0\n",
      "  'How do you do that?' → Label: 0\n",
      "  'And give us a plan.' → Label: 0\n",
      "  'I see what it does.' → Label: 0\n",
      "  'Yes, I think it is.' → Label: 0\n",
      "\n",
      "5. DUPLICATE ANALYSIS:\n",
      "Total duplicate texts: 25233\n",
      "Sample duplicates with different labels:\n"
     ]
    }
   ],
   "source": [
    "print(\"=== CLAIMBUSTERS DATA QUALITY ANALYSIS ===\\n\")\n",
    "\n",
    "# 1. Check label distribution\n",
    "print(\"1. LABEL DISTRIBUTION:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Claims (LABEL_1): {len(df[df['label'] == 1])} ({len(df[df['label'] == 1])/len(df)*100:.1f}%)\")\n",
    "print(f\"Non-claims (LABEL_0): {len(df[df['label'] == 0])} ({len(df[df['label'] == 0])/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 2. Look at clearly factual statements that are labeled as non-claims\n",
    "print(\"\\n2. SUSPICIOUS NON-CLAIM LABELS (should probably be claims):\")\n",
    "factual_patterns = [\n",
    "    r'\\b\\d{4}\\b',  # Years\n",
    "    r'\\b\\d+%\\b',   # Percentages  \n",
    "    r'\\$\\d+',      # Dollar amounts\n",
    "    r'\\b\\d+\\.\\d+\\b', # Decimal numbers\n",
    "    r'\\bwas\\s+(president|senator|governor|born|elected)\\b',  # Factual verbs\n",
    "    r'\\bin\\s+\\d{4}\\b',  # \"in [year]\"\n",
    "]\n",
    "\n",
    "suspicious_non_claims = []\n",
    "for _, row in df[df['label'] == 0].iterrows():\n",
    "    text = row['text'].lower()\n",
    "    for pattern in factual_patterns:\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            suspicious_non_claims.append(row['text'])\n",
    "            break\n",
    "\n",
    "print(f\"Found {len(suspicious_non_claims)} suspicious non-claim labels\")\n",
    "print(\"Sample suspicious non-claims:\")\n",
    "for i, text in enumerate(suspicious_non_claims[:15], 1):\n",
    "    print(f\"{i:2d}. {text}\")\n",
    "\n",
    "# 3. Look at claims that seem like opinions\n",
    "print(\"\\n3. SUSPICIOUS CLAIM LABELS (should probably be non-claims):\")\n",
    "opinion_patterns = [\n",
    "    r'\\b(best|worst|great|terrible|amazing|awful)\\b',\n",
    "    r'\\b(should|must|need to|have to)\\b',\n",
    "    r'\\b(beautiful|ugly|smart|stupid)\\b',\n",
    "    r'\\b(love|hate|like|dislike)\\b',\n",
    "    r'\\b(believe|think|feel)\\b',\n",
    "]\n",
    "\n",
    "suspicious_claims = []\n",
    "for _, row in df[df['label'] == 1].iterrows():\n",
    "    text = row['text'].lower()\n",
    "    for pattern in opinion_patterns:\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            suspicious_claims.append(row['text'])\n",
    "            break\n",
    "\n",
    "print(f\"Found {len(suspicious_claims)} suspicious claim labels\")\n",
    "print(\"Sample suspicious claims:\")\n",
    "for i, text in enumerate(suspicious_claims[:15], 1):\n",
    "    print(f\"{i:2d}. {text}\")\n",
    "\n",
    "# 4. Check for very short or very long samples\n",
    "print(\"\\n4. SAMPLE LENGTH ANALYSIS:\")\n",
    "df['length'] = df['text'].str.len()\n",
    "print(f\"Average text length: {df['length'].mean():.1f} characters\")\n",
    "print(f\"Shortest text: {df['length'].min()} chars\")\n",
    "print(f\"Longest text: {df['length'].max()} chars\")\n",
    "\n",
    "# Show very short samples\n",
    "short_samples = df[df['length'] < 20]\n",
    "print(f\"\\nVery short samples ({len(short_samples)}):\")\n",
    "for _, row in short_samples.head(10).iterrows():\n",
    "    print(f\"  '{row['text']}' → Label: {row['label']}\")\n",
    "\n",
    "# 5. Check for exact duplicates\n",
    "print(f\"\\n5. DUPLICATE ANALYSIS:\")\n",
    "duplicates = df[df.duplicated(subset=['text'], keep=False)]\n",
    "print(f\"Total duplicate texts: {len(duplicates)}\")\n",
    "if len(duplicates) > 0:\n",
    "    print(\"Sample duplicates with different labels:\")\n",
    "    for text in duplicates['text'].unique()[:5]:\n",
    "        text_samples = df[df['text'] == text]\n",
    "        labels = text_samples['label'].unique()\n",
    "        if len(labels) > 1:\n",
    "            print(f\"  '{text}' has labels: {labels}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
