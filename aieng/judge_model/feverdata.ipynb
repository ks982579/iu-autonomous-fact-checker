{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "652b349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af449963",
   "metadata": {},
   "source": [
    "The following is just a work in progress - but this config will help for building and testing I hope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec004d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileConfig:\n",
    "    __FullRunContext = \"\"\"denotes using the complete dataset of just a smaller portion of it for testing.\"\"\"\n",
    "    FullRun = False\n",
    "\n",
    "    __Percentage = \"\"\"If NOT a full run, what percentage of data do we use? (Think decimal values 0 < pc < 1)\"\"\"\n",
    "    Percentage = 0.1\n",
    "    \n",
    "    __ToBuildContext = \"\"\"Do we want to build another model or run without build for testing purposes.\"\"\"\n",
    "    ToBuild = True\n",
    "\n",
    "    __CustomLossFnContext = \"\"\"For certain cases with class imbalance we need a custom loss function.\"\"\"\n",
    "    CustomLossFn = False\n",
    "\n",
    "    BaseModelName = \"bert-base-uncased\"\n",
    "\n",
    "# class Labels(Enum)\n",
    "LabelMap = Enum(\n",
    "    'LabelMap', \n",
    "    [\n",
    "        ('SUPPORTS', 0),\n",
    "        ('REFUTES', 1),\n",
    "        ('NOT ENOUGH INFO', 2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ac2305bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL_RUN denotes using all the dataset or a small bit of it for testing the process\n",
    "FULL_RUN = False\n",
    "MODEL_VERSION = \"v0.1.3\"\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76affa0",
   "metadata": {},
   "source": [
    "Turned out the database was 52GB of Wikipedia articles, but the dataset fit OK in one file so chunking wasn't necessary...\n",
    "Keeping the logic though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d502a8d",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "The data had to be processed on my Windows laptop since the wiki DB was over 50GB large and I wasn't transfering to WSL.\n",
    "I was able to create Parquet files which are good at storage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "218cba25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading 1 chunks from /home/ksull18/code/iu-autonomous-fact-checker/aieng/judge_model/.datasets/processed\n",
      "INFO:__main__:Loaded fever_train_chunk_0000.parquet: 48205 samples\n",
      "INFO:__main__:Total samples loaded: 48205\n",
      "INFO:__main__:Loading 1 chunks from /home/ksull18/code/iu-autonomous-fact-checker/aieng/judge_model/.datasets/processed\n",
      "INFO:__main__:Loaded fever_dev_chunk_0000.parquet: 5363 samples\n",
      "INFO:__main__:Total samples loaded: 5363\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>claim</th>\n",
       "      <th>evidence</th>\n",
       "      <th>label</th>\n",
       "      <th>challenge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14802</td>\n",
       "      <td>Asiatic Society of Bangladesh(housed in Nimtal...</td>\n",
       "      <td>[The society is housed in Nimtali, walking dis...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28540</td>\n",
       "      <td>Lindfield railway station has 3 bus routes, in...</td>\n",
       "      <td>[Lindfield Station is served by three bus rout...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71874</td>\n",
       "      <td>Mukaradeeb('Wolf's Den') is a city in Iraq nea...</td>\n",
       "      <td>['Wolf's Den') is a small village in Iraq near...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>combining tables and text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70296</td>\n",
       "      <td>Herbivore men was coined by Maki Fukasawa and ...</td>\n",
       "      <td>[The term was coined by the author Maki Fukasa...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>multi-hop reasoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16578</td>\n",
       "      <td>Shulin, a 33.1288 km (12.7911 sq mi) land loca...</td>\n",
       "      <td>['forest district') is an inner city district ...</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              claim  \\\n",
       "0  14802  Asiatic Society of Bangladesh(housed in Nimtal...   \n",
       "1  28540  Lindfield railway station has 3 bus routes, in...   \n",
       "2  71874  Mukaradeeb('Wolf's Den') is a city in Iraq nea...   \n",
       "3  70296  Herbivore men was coined by Maki Fukasawa and ...   \n",
       "4  16578  Shulin, a 33.1288 km (12.7911 sq mi) land loca...   \n",
       "\n",
       "                                            evidence     label  \\\n",
       "0  [The society is housed in Nimtali, walking dis...  SUPPORTS   \n",
       "1  [Lindfield Station is served by three bus rout...  SUPPORTS   \n",
       "2  ['Wolf's Den') is a small village in Iraq near...  SUPPORTS   \n",
       "3  [The term was coined by the author Maki Fukasa...  SUPPORTS   \n",
       "4  ['forest district') is an inner city district ...   REFUTES   \n",
       "\n",
       "                   challenge  \n",
       "0                      other  \n",
       "1                      other  \n",
       "2  combining tables and text  \n",
       "3        multi-hop reasoning  \n",
       "4                      other  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_processed_fever(output_dir: Path, filestart: str,  max_chunks=None):\n",
    "    \"\"\"\n",
    "    Load processed FEVER data from disk\n",
    "    \n",
    "    Args:\n",
    "        output_dir: Directory containing processed chunks\n",
    "        max_chunks: Maximum number of chunks to load (None for all)\n",
    "    \"\"\"\n",
    "    output_path = Path(output_dir).resolve()\n",
    "    assert output_path.exists()\n",
    "    \n",
    "    # Find all parquet files\n",
    "    parquet_files = sorted(output_path.glob(f\"{filestart}*.parquet\"))\n",
    "    \n",
    "    if max_chunks:\n",
    "        parquet_files = parquet_files[:max_chunks]\n",
    "    \n",
    "    logger.info(f\"Loading {len(parquet_files)} chunks from {output_path}\")\n",
    "    \n",
    "    # Load and combine all chunks\n",
    "    dfs = []\n",
    "    for file in parquet_files:\n",
    "        df = pd.read_parquet(file)\n",
    "        dfs.append(df)\n",
    "        logger.info(f\"Loaded {file.name}: {len(df)} samples\")\n",
    "    \n",
    "    if dfs:\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "        logger.info(f\"Total samples loaded: {len(combined_df)}\")\n",
    "        return Dataset.from_pandas(combined_df)\n",
    "    else:\n",
    "        logger.warning(\"No data files found!\")\n",
    "        return None\n",
    "    \n",
    "# processed_data_home = Path(__file__).resolve().parent / '.datasets' / 'processed'\n",
    "processed_data_home = Path('.').resolve() / '.datasets' / 'processed'\n",
    "pds = load_processed_fever(processed_data_home, 'fever_train_chunk')\n",
    "pdft = pd.DataFrame(pds)\n",
    "pds = load_processed_fever(processed_data_home, 'fever_dev_chunk')\n",
    "pdfd = pd.DataFrame(pds)\n",
    "pdft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fa25d7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "SUPPORTS           31811\n",
      "REFUTES            14610\n",
      "NOT ENOUGH INFO     1784\n",
      "Name: count, dtype: int64\n",
      "48205\n"
     ]
    }
   ],
   "source": [
    "print(pdft['label'].value_counts())\n",
    "print(len(pdft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "86a18532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The society is housed in Nimtali, walking distance from the Curzon Hall of Dhaka University, locality of Old Dhaka.', 'The Asiatic Society of Bangladesh is a non political and non profit research organisation registered under both Society Act of 1864 and NGO Bureau, Government of Bangladesh.', 'The Asiatic Society of Bangladesh was established as the Asiatic Society of East Pakistan in Dhaka in 1952 by numbers of Muslim leaders, and renamed in 1972.', 'Ahmed Hasan Dani, a noted Muslim historian and archaeologist of Pakistan played an important role in founding this society.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pdft['evidence'][0])\n",
    "type(pdft['evidence'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1e55629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "48200    False\n",
      "48201    False\n",
      "48202    False\n",
      "48203    False\n",
      "48204    False\n",
      "Name: label, Length: 48205, dtype: bool\n",
      "40.) Cameroon lists three definitely endangered languages, 13 severely endangered, and 16 critically endangered from among its at least 250 languages.\n",
      "Evidence:\n",
      "  Cameroon is home to at least 250 languages.\n",
      "------------------------------\n",
      "57.) Alan Lowry only played games with his close relatives in his entire life.\n",
      "Evidence:\n",
      "  Running back Roosevelt Leaks also ran for more than 100 yards in that game, making it the first time Texas had two 100-yard rushers in the same bowl game.\n",
      "  Born and raised in Brenham, Texas, between Houston and Austin, Leaks grew up on his family's farm, where they raised, among other things, cotton and corn.\n",
      "  Alan Lowry grew up in Irving, Texas.\n",
      "------------------------------\n",
      "94.) A Distributed Bragg Reflector laser has diffraction grating on one or both end mirrors, which reflect a narrow band of light back in the cavity which help them be more spectrally stable.\n",
      "Evidence:\n",
      "  A resonant cavity is defined by a highly reflective DBR mirror on one end, and a low reflectivity cleaved exit facet on the other end.\n",
      "  So DBR lasers tend to be more spectrally stable than Fabry-Perot lasers with broadband coatings.\n",
      "  These longitudinal diffraction grating mirrors reflect the light back in the cavity, very much like a multi-layer mirror coating.\n",
      "  If one or both of these end mirrors are replaced with a diffraction grating, the structure is then known as a DBR laser (Distributed Bragg Reflector).\n",
      "  The diffraction grating mirrors tend to reflect a narrower band of wavelengths than normal end mirrors, and this limits the number of standing waves that can be supported by the gain in the cavity.\n",
      "------------------------------\n",
      "138.) Nucleoporin 153, a protein which in reptiles is encoded by the NUP153 gene, is an essential component of the basket of nuclear pore complexes (NPCs) in vertebrates, and required for the anchoring of NPCs.\n",
      "Evidence:\n",
      "  Nucleoporin 153 (Nup153) is a protein which in humans is encoded by the NUP153 gene.\n",
      "  It is an essential component of the basket of nuclear pore complexes (NPCs) in vertebrates, and required for the anchoring of NPCs.\n",
      "------------------------------\n",
      "141.) Rick ten Voorde played so well in the preseason matches, which resulted in a call-up for the National Under 21-football team as 18-year-old player and was the youngest player of this team.\n",
      "Evidence:\n",
      "  He played so well in the preseason matches, which resulted in a call-up for the National Under 21-football team as 18-year-old player.\n",
      "  Ten Voorde is currently the youngest player of this team.\n",
      "------------------------------\n",
      "143.) Frederick Borden, the Minister of Militia and Defence, announced in May that a 200-strong force would be deployed to Fort Selkirk; and one of the arguments put forward in favour of this option was that it was much cheaper than sending additional police, who enjoyed higher pay than soldiers.\n",
      "Evidence:\n",
      "  While he was the Minister for Militia and Defence, he was the father of the most famous Canadian casualty of the Second Boer War Harold Lothrop Borden.\n",
      "  Following the succession of King Edward VII and the end of the Second Boer War by the Peace of Vereeniging in late May 1902, Borden was created a Knight Commander of the Order of St Michael and St George (KCMG) in the 1902 Coronation Honours list published on 26 June 1902.\n",
      "  He attended the fleet review held at Spithead on 16 August 1902 to mark the coronation, and received the order in an investiture on board the royal yacht Victoria and Albert the previous day.\n",
      "------------------------------\n",
      "148.) Mark Solonin, born on April 29, 1958 at Kuybyshev, Russian SFSR, Soviet Union, is a Russian historian focused on Soviet history who studied at University of the Philippines.\n",
      "Evidence:\n",
      "  Mark Solonin (born May 29, 1958, in Kuybyshev, USSR) is a Russian historian, and author who writes about the history of World War II.\n",
      "------------------------------\n",
      "159.) Lannone had raced in several MotoGP championship, (Grand Prix motorcycle racing is the premier class of motorcycle road racing events held on road circuits) and had a total of 13 winnings,  61% of which was winnings in the class Moto2 race, however, 45% of his total points are obtained in the class MotoGP.\n",
      "Evidence:\n",
      "  Grand Prix motorcycle racing is the premier championship of motorcycle road racing, which has been divided into three classes since 1990; 125cc, 250cc and MotoGP.\n",
      "  Road racing is a form of motorsport racing held on a paved road surfaces.\n",
      "  The races can be held either on a closed circuit or on a street circuit utilizing temporarily closed public roads.\n",
      "  Patrick Iannone is a Canadian-born Italian professional ice hockey player who participated at the 2010 IIHF World Championship as a member of the Italian National men's ice hockey team.\n",
      "  Phil Read and Max Biaggi have won the most 250cc/Moto2 championships, with four victories each.\n",
      "  The following is a list of FIM Grand Prix motorcycle racing World Champions from 1949 to 2019, in order of class and year.\n",
      "------------------------------\n",
      "168.) Kewal Singh (an Indian diplomat, Foreign Treasurer and India's ambassador to the USSR, Pakistan and USA) took office on October 21, 1954 then left on November 16, 1956; before M.K. Kripalani took over on November 17, 1956.\n",
      "Evidence:\n",
      "  Kewal Singh (1915–1991) was an Indian diplomat, Foreign Secretary and India's ambassador to the USSR, Pakistan and USA.\n",
      "------------------------------\n",
      "213.) Edvin Biuković was a Croatian penciller, a collaboration artist who works in creation of comic books, graphic novels, and similar visual art forms, who died on December 5, 1999.\n",
      "Evidence:\n",
      "  Edvin Biuković (June 22, 1969 – December 5, 1999) was a Croatian comics artist.\n",
      "  He spent several more years working on comic projects in Croatia and collaborated with his good friend Darko Macan on the pages of German magazine Gespenster Geschichten.\n",
      "  His big break came in 1994 when Dark Horse published Grendel Tales: Devils and Deaths, his another collaboration with Macan.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# what is not enough data?\n",
    "mask = pdft[\"label\"] == \"NOT ENOUGH INFO\"\n",
    "print(mask)\n",
    "baddf = pdft[mask]\n",
    "\n",
    "# could also go with iloc\n",
    "for index, row in baddf.head(10).iterrows():\n",
    "    print(f\"{index + 1}.) {row['claim']}\")\n",
    "    print(\"Evidence:\")\n",
    "    for t in row['evidence']:\n",
    "        print(f\"  {t}\")\n",
    "    print(\"---\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f2b0b",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "Going to follow pretty close to how I trained the claim extractor / detector model.\n",
    "Going to finetune BERT first I think as the context might not be big enough in DistilBERT for the evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb362d6",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "I organized the data while processing the WikiDB and training and dev files.\n",
    "The data is off balance but I will try to use what I have before making further altercations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7b55f133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA IS LOADED IN FROM ABOVE: it is already split into different files as well.\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA IS LOADED IN FROM ABOVE: it is already split into different files as well.\")\n",
    "\n",
    "# Data Shuffle\n",
    "for _ in range(3):\n",
    "    pdft = pdft.sample(frac=1, replace=False, ignore_index=True)\n",
    "    pdfd = pdfd.sample(frac=1, replace=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc35f72",
   "metadata": {},
   "source": [
    "## Loading and Setup with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d61b1",
   "metadata": {},
   "source": [
    "### Initialize Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7fab1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06423edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPECIAL_TOKENS_ATTRIBUTES',\n",
       " '__annotations__',\n",
       " '__bool__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_tokens',\n",
       " '_auto_class',\n",
       " '_batch_encode_plus',\n",
       " '_call_one',\n",
       " '_convert_encoding',\n",
       " '_convert_id_to_token',\n",
       " '_convert_token_to_id_with_added_voc',\n",
       " '_create_repo',\n",
       " '_decode',\n",
       " '_decode_use_source_tokenizer',\n",
       " '_encode_plus',\n",
       " '_eventual_warn_about_too_long_sequence',\n",
       " '_eventually_correct_t5_max_length',\n",
       " '_from_pretrained',\n",
       " '_get_files_timestamps',\n",
       " '_get_padding_truncation_strategies',\n",
       " '_in_target_context_manager',\n",
       " '_pad',\n",
       " '_pad_token_type_id',\n",
       " '_processor_class',\n",
       " '_save_pretrained',\n",
       " '_set_model_specific_special_tokens',\n",
       " '_set_processor_class',\n",
       " '_special_tokens_map',\n",
       " '_switch_to_input_mode',\n",
       " '_switch_to_target_mode',\n",
       " '_tokenizer',\n",
       " '_upload_modified_files',\n",
       " 'add_prefix_space',\n",
       " 'add_special_tokens',\n",
       " 'add_tokens',\n",
       " 'added_tokens_decoder',\n",
       " 'added_tokens_encoder',\n",
       " 'all_special_ids',\n",
       " 'all_special_tokens',\n",
       " 'all_special_tokens_extended',\n",
       " 'apply_chat_template',\n",
       " 'as_target_tokenizer',\n",
       " 'backend_tokenizer',\n",
       " 'batch_decode',\n",
       " 'batch_encode_plus',\n",
       " 'build_inputs_with_special_tokens',\n",
       " 'can_save_slow_tokenizer',\n",
       " 'chat_template',\n",
       " 'clean_up_tokenization',\n",
       " 'clean_up_tokenization_spaces',\n",
       " 'convert_added_tokens',\n",
       " 'convert_ids_to_tokens',\n",
       " 'convert_tokens_to_ids',\n",
       " 'convert_tokens_to_string',\n",
       " 'create_token_type_ids_from_sequences',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'deprecation_warnings',\n",
       " 'do_lower_case',\n",
       " 'encode',\n",
       " 'encode_plus',\n",
       " 'extra_special_tokens',\n",
       " 'from_pretrained',\n",
       " 'get_added_vocab',\n",
       " 'get_chat_template',\n",
       " 'get_special_tokens_mask',\n",
       " 'get_vocab',\n",
       " 'init_inputs',\n",
       " 'init_kwargs',\n",
       " 'is_fast',\n",
       " 'max_len_sentences_pair',\n",
       " 'max_len_single_sentence',\n",
       " 'model_input_names',\n",
       " 'model_max_length',\n",
       " 'name_or_path',\n",
       " 'num_special_tokens_to_add',\n",
       " 'pad',\n",
       " 'pad_token_type_id',\n",
       " 'padding_side',\n",
       " 'prepare_for_model',\n",
       " 'prepare_seq2seq_batch',\n",
       " 'pretrained_vocab_files_map',\n",
       " 'push_to_hub',\n",
       " 'register_for_auto_class',\n",
       " 'sanitize_special_tokens',\n",
       " 'save_chat_templates',\n",
       " 'save_pretrained',\n",
       " 'save_vocabulary',\n",
       " 'set_truncation_and_padding',\n",
       " 'slow_tokenizer_class',\n",
       " 'special_tokens_map',\n",
       " 'special_tokens_map_extended',\n",
       " 'split_special_tokens',\n",
       " 'tokenize',\n",
       " 'train_new_from_iterator',\n",
       " 'truncate_sequences',\n",
       " 'truncation_side',\n",
       " 'verbose',\n",
       " 'vocab',\n",
       " 'vocab_files_names',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading tokenizer for this model\n",
    "tokenizer = AutoTokenizer.from_pretrained(FileConfig.BaseModelName)\n",
    "dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "55f02269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ran into tokenization issue - All tensors in a batch should be same length\n",
    "# Some were 100 and but one was 187.\n",
    "# Use padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ee00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: bert-base-uncased\n",
      "Vocabulary size: 30522\n"
     ]
    }
   ],
   "source": [
    "# Loading Model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    FileConfig.BaseModelName, \n",
    "    num_labels=3,  # Yay, Nay, Not enough info\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model loaded: {FileConfig.BaseModelName}\")\n",
    "print(f\"Vocabulary size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60924fa3",
   "metadata": {},
   "source": [
    "### Tokenize Data\n",
    "\n",
    "Unlike the claim_extractor model, which just had the claim and a label, this model has claims and evidence, and 3 labels. \n",
    "I believe our tokenizer must handle the proper combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ec05c",
   "metadata": {},
   "source": [
    "> Perhaps a point of improvement - better input and separation of claims and evidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca1c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform(claim: str, evidence: List[str]):\n",
    "    \"\"\"\n",
    "    This will be used later when we need to actually use this model.\n",
    "    \"\"\"\n",
    "    if isinstance(evidence, list):\n",
    "        evidence_text = \" \".join(evidence)\n",
    "    else:\n",
    "        evidence_text = str(evidence)\n",
    "    \n",
    "    # Update for BERT Specific\n",
    "    return f\"[CLS] CLAIM: {claim} [SEP] EVIDENCE: {evidence_text} [SEP]\"\n",
    "    # return f\"CLAIM: {claim} EVIDENCE: {evidence_text}\"\n",
    "\n",
    "def tokenize_fn(dataset):\n",
    "    # Combine claim and evidence into single text input\n",
    "    texts = []\n",
    "    for claim, evidence in zip(dataset['claim'], dataset['evidence']):\n",
    "        combined_text = data_transform(claim, evidence)\n",
    "        texts.append(combined_text)\n",
    "\n",
    "    # Due to issues around tensor length - get actual max length or default to what worked.\n",
    "    max_len = getattr(tokenizer, 'model_max_length', 512)\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        # Tensor Size returned is 1021 and doesn't match the 512...\n",
    "        # max_length=(2**10)\n",
    "        max_length=512,\n",
    "        # return_tensors=None, # not necessary once correct lenght established\n",
    "    )\n",
    "\n",
    "    label_map = {\"SUPPORTS\": 0, \"REFUTES\": 1, \"NOT ENOUGH INFO\": 2}\n",
    "    if isinstance(dataset['label'], list):\n",
    "        # batched\n",
    "        model_inputs[\"label\"] = [label_map[label] for label in dataset['label']]\n",
    "    else:\n",
    "        model_inputs[\"label\"] = [label_map[dataset['label']]]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a536ed82",
   "metadata": {},
   "source": [
    "#### Data Debugging\n",
    "\n",
    "The training is not working because it says the labels are a list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1aac0686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rows from pdft:\n",
      "                                               claim  \\\n",
      "0  Paulie Gilmore, born James E. Allen from Bosto...   \n",
      "1  MassResistance is a political activist group w...   \n",
      "\n",
      "                                            evidence     label  \n",
      "0  [James E. Allen is an American professional wr...  SUPPORTS  \n",
      "1  [MassResistance is a hate group which promotes...   REFUTES  \n",
      "\n",
      "Data types:\n",
      "claim       object\n",
      "evidence    object\n",
      "label       object\n",
      "dtype: object\n",
      "\n",
      "Sample evidence type:\n",
      "<class 'list'>\n",
      "Sample evidence content:\n",
      "['James E. Allen is an American professional wrestler and promoter, best known by his ringname \"Big\" Paulie Gilmore or Gilmorea, who wrestled on the New England independent circuit for the Century Wrestling Alliance, the National Wrestling Alliance, the Millennium Wrestling Federation and the World Wrestling Alliance during the 1990s and early 2000s.', 'James E. Allen made his debut in 1994 and spent a brief time on the local independent circuit prior to joining the Century Wrestling Alliance in 1996.']\n",
      "\n",
      "Sample label type:\n",
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>evidence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paulie Gilmore, born James E. Allen from Bosto...</td>\n",
       "      <td>[James E. Allen is an American professional wr...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MassResistance is a political activist group w...</td>\n",
       "      <td>[MassResistance is a hate group which promotes...</td>\n",
       "      <td>REFUTES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  \\\n",
       "0  Paulie Gilmore, born James E. Allen from Bosto...   \n",
       "1  MassResistance is a political activist group w...   \n",
       "\n",
       "                                            evidence     label  \n",
       "0  [James E. Allen is an American professional wr...  SUPPORTS  \n",
       "1  [MassResistance is a hate group which promotes...   REFUTES  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the structure of your pandas data before conversion\n",
    "print(\"Sample rows from pdft:\")\n",
    "print(pdft[['claim', 'evidence', 'label']].head(2))\n",
    "print(\"\\nData types:\")\n",
    "print(pdft[['claim', 'evidence', 'label']].dtypes)\n",
    "print(\"\\nSample evidence type:\")\n",
    "print(type(pdft['evidence'].iloc[0]))\n",
    "print(\"Sample evidence content:\")\n",
    "print(pdft['evidence'].iloc[0])\n",
    "print(\"\\nSample label type:\")\n",
    "print(type(pdft['label'].iloc[0]))\n",
    "pdft[['claim', 'evidence', 'label']].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb3dfb",
   "metadata": {},
   "source": [
    "### Constant...\n",
    "\n",
    "LABELS is for computing class weights later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3b7f09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = pdft['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "60cf4f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1784"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(pdft['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56790281",
   "metadata": {},
   "source": [
    "[This StackOverflow post](https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows) lists several ways to shuffle a dataframe. \n",
    "Pandas has the builtin `df = df.sample(frac=1).reset_index(drop=True)` which apparently reassigns but does not recreate.\n",
    "SciKit Learn also has a \"shuffle\" method but that might require resetting indexes.\n",
    "There are then seemingly countless ways after that as well...\n",
    "\n",
    "Side note on sample - it now has an 'ignore_index' param to help with that reset issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3fc081bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial Run of 10.00%\n",
      "label\n",
      "REFUTES            3568\n",
      "SUPPORTS           3568\n",
      "NOT ENOUGH INFO    3568\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "SUPPORTS           3000\n",
      "REFUTES            1947\n",
      "NOT ENOUGH INFO     416\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10704/10704 [00:02<00:00, 4343.91 examples/s]\n",
      "Map: 100%|██████████| 5363/5363 [00:05<00:00, 1014.38 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data tokenized successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to 🤗 Dataset objects\n",
    "if FileConfig.FullRun:\n",
    "    print(\"Full Run!\")\n",
    "    dst = Dataset.from_pandas(pdft[['claim', 'evidence', 'label']])\n",
    "    dsv = Dataset.from_pandas(pdfd[['claim', 'evidence', 'label']])\n",
    "else:\n",
    "    # mini-datasets for running into issues... 😖\n",
    "    # should probably go in the data processing section\n",
    "    pc = FileConfig.Percentage\n",
    "    print(f\"Partial Run of {pc:.02%}\")\n",
    "\n",
    "    # there's probably an easier way...\n",
    "    # training_mini = pd.concat([\n",
    "    #     pdft[pdft['label'] == 'SUPPORTS'].sample(frac=pc, replace=False, ignore_index=True),\n",
    "    #     pdft[pdft['label'] == 'REFUTES'].sample(frac=pc, replace=False, ignore_index=True),\n",
    "    #     pdft[pdft['label'] == 'NOT ENOUGH INFO'].sample(frac=pc, replace=False, ignore_index=True),\n",
    "    # ])\n",
    "\n",
    "    # val_mini = pd.concat([\n",
    "    #     pdfd[pdfd['label'] == 'SUPPORTS'].sample(frac=pc, replace=False, ignore_index=True),\n",
    "    #     pdfd[pdfd['label'] == 'REFUTES'].sample(frac=pc, replace=False, ignore_index=True),\n",
    "    #     pdfd[pdfd['label'] == 'NOT ENOUGH INFO'].sample(frac=pc, replace=False, ignore_index=True),\n",
    "    # ])\n",
    "\n",
    "    # NEW STRATEGY\n",
    "    numr = min(pdft['label'].value_counts()) * 2\n",
    "    training_mini = pd.concat([\n",
    "        pdft[pdft['label'] == 'SUPPORTS'].sample(n=numr, replace=False, ignore_index=True),\n",
    "        pdft[pdft['label'] == 'REFUTES'].sample(n=numr, replace=False, ignore_index=True),\n",
    "        # allowing replacement here.\n",
    "        pdft[pdft['label'] == 'NOT ENOUGH INFO'].sample(n=numr, replace=True, ignore_index=True),\n",
    "    ])\n",
    "\n",
    "    val_mini = pd.concat([\n",
    "        pdfd[pdfd['label'] == 'SUPPORTS'].sample(frac=1, replace=False, ignore_index=True),\n",
    "        pdfd[pdfd['label'] == 'REFUTES'].sample(frac=1, replace=False, ignore_index=True),\n",
    "        pdfd[pdfd['label'] == 'NOT ENOUGH INFO'].sample(frac=1, replace=False, ignore_index=True),\n",
    "    ])\n",
    "\n",
    "    # Shuffling / Randomizing data\n",
    "    for _ in range(5):\n",
    "        training_mini = training_mini.sample(frac=1, replace=False, ignore_index=True)\n",
    "        val_mini = val_mini.sample(frac=1, replace=False, ignore_index=True)\n",
    "\n",
    "    print(training_mini['label'].value_counts())\n",
    "    print(val_mini['label'].value_counts())\n",
    "    dst = Dataset.from_pandas(training_mini[['claim', 'evidence', 'label']])\n",
    "    dsv = Dataset.from_pandas(val_mini[['claim', 'evidence', 'label']])\n",
    "\n",
    "    ## REDO Labels - shouldn't be too different\n",
    "    LABLES = training_mini['label'].values\n",
    "\n",
    "# Apply tokenization\n",
    "train_dataset = dst.map(\n",
    "    tokenize_fn, \n",
    "    batched=True,\n",
    "    remove_columns=dst.column_names,\n",
    ")\n",
    "val_dataset = dsv.map(\n",
    "    tokenize_fn, \n",
    "    batched=True,\n",
    "    remove_columns=dsv.column_names,\n",
    ")\n",
    "\n",
    "print(\"Data tokenized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "299c9ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77ab62",
   "metadata": {},
   "source": [
    "The below helped me find a mismatch in data-types between the dataset I thought I was making and what was really created...\n",
    "which the training did not like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b9b38ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset columns: ['claim', 'evidence', 'label']\n",
      "Dataset features: {'claim': Value('string'), 'evidence': List(Value('string')), 'label': Value('string')}\n",
      "First example:\n",
      "{'claim': 'Bernie Sanders, former Mayor of Burlington, Vermont lost to Dolores Sandoval as the Democratic bet for the 1990 US House of Representatives election in Vermont.', 'evidence': [\"He won election to the U.S. House of Representatives in 1990, representing Vermont's at-large congressional district, later co-founding the Congressional Progressive Caucus.\"], 'label': 'REFUTES'}\n",
      "Column 'claim' type: <class 'datasets.arrow_dataset.Column'>\n",
      "First value: Bernie Sanders, former Mayor of Burlington, Vermont lost to Dolores Sandoval as the Democratic bet for the 1990 US House of Representatives election in Vermont.\n",
      "First value type: <class 'str'>\n",
      "---\n",
      "Column 'evidence' type: <class 'datasets.arrow_dataset.Column'>\n",
      "First value: [\"He won election to the U.S. House of Representatives in 1990, representing Vermont's at-large congressional district, later co-founding the Congressional Progressive Caucus.\"]\n",
      "First value type: <class 'list'>\n",
      "---\n",
      "Column 'label' type: <class 'datasets.arrow_dataset.Column'>\n",
      "First value: REFUTES\n",
      "First value type: <class 'str'>\n",
      "---\n",
      "=========================\n",
      "Dataset columns: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "Dataset features: {'label': Value('int64'), 'input_ids': List(Value('int32')), 'token_type_ids': List(Value('int8')), 'attention_mask': List(Value('int8'))}\n",
      "First example:\n",
      "{'label': 1, 'input_ids': [101, 4366, 1024, 15941, 12055, 1010, 2280, 3664, 1997, 15552, 1010, 8839, 2439, 2000, 21544, 5472, 7103, 2140, 2004, 1996, 3537, 6655, 2005, 1996, 2901, 2149, 2160, 1997, 4505, 2602, 1999, 8839, 1012, 3350, 1024, 2002, 2180, 2602, 2000, 1996, 1057, 1012, 1055, 1012, 2160, 1997, 4505, 1999, 2901, 1010, 5052, 8839, 1005, 1055, 2012, 1011, 2312, 7740, 2212, 1010, 2101, 2522, 1011, 4889, 1996, 7740, 6555, 13965, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Column 'label' type: <class 'datasets.arrow_dataset.Column'>\n",
      "First value: 1\n",
      "First value type: <class 'int'>\n",
      "---\n",
      "Column 'input_ids' type: <class 'datasets.arrow_dataset.Column'>\n",
      "First value: [101, 4366, 1024, 15941, 12055, 1010, 2280, 3664, 1997, 15552, 1010, 8839, 2439, 2000, 21544, 5472, 7103, 2140, 2004, 1996, 3537, 6655, 2005, 1996, 2901, 2149, 2160, 1997, 4505, 2602, 1999, 8839, 1012, 3350, 1024, 2002, 2180, 2602, 2000, 1996, 1057, 1012, 1055, 1012, 2160, 1997, 4505, 1999, 2901, 1010, 5052, 8839, 1005, 1055, 2012, 1011, 2312, 7740, 2212, 1010, 2101, 2522, 1011, 4889, 1996, 7740, 6555, 13965, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "First value type: <class 'list'>\n",
      "---\n",
      "Column 'token_type_ids' type: <class 'datasets.arrow_dataset.Column'>\n",
      "First value: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "First value type: <class 'list'>\n",
      "---\n",
      "Column 'attention_mask' type: <class 'datasets.arrow_dataset.Column'>\n",
      "First value: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "First value type: <class 'list'>\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Check the dataset structure after conversion from pandas\n",
    "print(\"Dataset columns:\", dst.column_names)\n",
    "print(\"Dataset features:\", dst.features)\n",
    "print(\"First example:\")\n",
    "try:\n",
    "    print(dst[0])\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing first example: {e}\")\n",
    "\n",
    "# Check if there are any problematic column names or types\n",
    "for col in dst.column_names:\n",
    "    print(f\"Column '{col}' type: {type(dst[col])}\")\n",
    "    try:\n",
    "        print(f\"First value: {dst[col][0]}\")\n",
    "        print(f\"First value type: {type(dst[col][0])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing column '{col}': {e}\")\n",
    "    print(\"---\")\n",
    "\n",
    "print(\"=\"*25)\n",
    "\n",
    "print(\"Dataset columns:\", train_dataset.column_names)\n",
    "print(\"Dataset features:\", train_dataset.features)\n",
    "print(\"First example:\")\n",
    "try:\n",
    "    print(train_dataset[0])\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing first example: {e}\")\n",
    "\n",
    "# Check if there are any problematic column names or types\n",
    "for col in train_dataset.column_names:\n",
    "    print(f\"Column '{col}' type: {type(train_dataset[col])}\")\n",
    "    try:\n",
    "        print(f\"First value: {train_dataset[col][0]}\")\n",
    "        print(f\"First value type: {type(train_dataset[col][0])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing column '{col}': {e}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e48a14",
   "metadata": {},
   "source": [
    "## Fine-Tune the Model\n",
    "\n",
    "We are doing **transfer learning** with **fine-tuning**. \n",
    "BERT was pre-trained to understand language - Thank you!\n",
    "We fine-tuning the model for a specific task - claim vs opinion here.\n",
    "The technique = Supervised learning with backpropagation\n",
    "\n",
    "Deep dive: BERT has millions of weights to understand language. We are adjusting these to suit our classification task. Only our final classification layer is learning from scratch. The rest of BERT is merely adapting instead of being completely retrained. \n",
    "BERT (I think) expects a \"[MASK]\" token to predict values. \n",
    "By fine-tuning, we add a layer like: `input text -> BERT Encoder -> Classification Head -> [Claim, Opinion] probabilities`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bb4d74",
   "metadata": {},
   "source": [
    "### Defining Training Arguments\n",
    "\n",
    "> I am taking most of this from the claim_extractor I made previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9cf2ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories for saving\n",
    "datenow = datetime.now()\n",
    "timestamp = datenow.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "# TODO: Give model name at top\n",
    "move_path = Path().cwd() / \"trainingresults\" / f'hide-bert_{timestamp}'\n",
    "out_path = Path().cwd() / \"trainingresults\" / \"latest\"\n",
    "metatdata_file_path = out_path / \"metadata.json\"\n",
    "\n",
    "# Below is the logic for moving previous versions\n",
    "if FileConfig.ToBuild:\n",
    "    if metatdata_file_path.exists():\n",
    "        # A model exists in latest already - move to it's timestamp\n",
    "\n",
    "        try:\n",
    "            with open(metatdata_file_path, 'r') as file:\n",
    "                tmp = json.load(file)\n",
    "                str_path = tmp.get('path', None)\n",
    "                assert str_path is not None\n",
    "                ts_path = Path(str_path)\n",
    "                # Moving the old model into its timestamp directory\n",
    "                out_path.rename(ts_path)\n",
    "        except Exception as e:\n",
    "            logger.warning(e)\n",
    "            # suggests something in directory didn't finish and should probably be deleted?\n",
    "        assert not out_path.exists()\n",
    "\n",
    "    ## Open cannot make the directories after I rename them...\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(out_path / \"metadata.json\", 'w') as file:\n",
    "        json.dump({\"path\": str(move_path), \"foundation\": model_name, 'timestamp': datenow.isoformat(), \"version\": MODEL_VERSION}, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f2e07f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLD\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=out_path, # Working directory during training for logs and checkpoints.\n",
    "#     num_train_epochs=3,              # Start with 3, adjust based on results\n",
    "#     ## batch size of 16 gets to 5.6/6GB of RTX 3060\n",
    "#     per_device_train_batch_size=8,  # Reduce if memory issues\n",
    "#     per_device_eval_batch_size=16,\n",
    "#     warmup_steps=500, # gradually increase learning rate over 1000 steps | prevents huge descrutive changes early on\n",
    "#     weight_decay=0.01, # Very mild 1% to prevent memorizing training data exactly. \n",
    "#     logging_dir='./logs',\n",
    "#     ## had set to 10 which is a lot of overhead\n",
    "#     logging_steps=20,\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"eval_loss\",\n",
    "#     greater_is_better=False,\n",
    "#     dataloader_pin_memory=False, # can help with GPU transfer speed\n",
    "#     fp16=True, # mixed precision can speedup training if supported\n",
    "#     dataloader_num_workers=4, # parallel data loading\n",
    "# )\n",
    "\n",
    "# New'ish\n",
    "# I increased Epochs and changed the saving and eval strategies to Steps\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=out_path, # Working directory during training for logs and checkpoints.\n",
    "    num_train_epochs=5,              # Start with 3, adjust based on results\n",
    "    ## batch size of 16 gets to 5.6/6GB of RTX 3060\n",
    "    per_device_train_batch_size=8,  # Reduce if memory issues\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=1000, # gradually increase learning rate over 1000 steps | prevents huge descrutive changes early on\n",
    "    weight_decay=0.01, # Very mild 1% to prevent memorizing training data exactly. \n",
    "    logging_dir='./logs',\n",
    "    ## had set to 10 which is a lot of overhead\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\", # Changing for balanced data\n",
    "    greater_is_better=True, # updated\n",
    "    dataloader_pin_memory=False, # can help with GPU transfer speed\n",
    "    fp16=True, # mixed precision can speedup training if supported\n",
    "    dataloader_num_workers=4, # parallel data loading\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e953c8bc",
   "metadata": {},
   "source": [
    "### Define Evaluation Metrics\n",
    "\n",
    "SciKit Learn has some handy prebuilt functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0fdec38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='weighted'\n",
    "    )\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7743b935",
   "metadata": {},
   "source": [
    "### Custome Weights\n",
    "\n",
    "The data is quite unbalanced.\n",
    "There is a total of 48,205 entries:\n",
    "- supports = 31,811\n",
    "- refutes = 14,610\n",
    "- na = 1,784\n",
    "\n",
    "Rebalancing to the tiny amount is not desireable.\n",
    "The `Trainer` can take in a loss function. The signature is just 'Callable' so inside the class it takes in `(outputs, labels, num_items_in_batch)`.\n",
    "\n",
    "There are several loss functions to consider:\n",
    "- \n",
    "\n",
    "\n",
    "[SciKit-Learn's `compute_class_weight`](https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html) function follows the inverse frequency approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ba354733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "LabelMap.SUPPORTS\n",
      "1\n",
      "LabelMap.REFUTES\n",
      "2\n",
      "LabelMap.NOT ENOUGH INFO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SUPPORTS'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for I,J in enumerate(LabelMap):\n",
    "    print(I)\n",
    "    print(str(J))\n",
    "\n",
    "LabelMap['SUPPORTS'].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "98748903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5051, 1.0998, 9.0069], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def create_weights(labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    weights_balanced = compute_class_weight('balanced', classes=unique_labels, y=labels)\n",
    "    weight_tensor = torch.zeros(3)\n",
    "\n",
    "    for index, en in enumerate(LabelMap):\n",
    "        label_inx = np.where(unique_labels == en.name)[0][0]\n",
    "        weight_tensor[index] = weights_balanced[label_inx]\n",
    "    \n",
    "    return weight_tensor\n",
    "\n",
    "class_weights = create_weights(LABELS)\n",
    "class_weights = class_weights.to(model.device)\n",
    "print(class_weights)\n",
    "\n",
    "# This needs work, I don't think weights should change nor be calucated during each batch...\n",
    "def custom_weighted_loss_fn(outputs, labels, num_items_in_batch=None):\n",
    "    logits = outputs.logits # Model's raw predictions [batch_size, 3]\n",
    "\n",
    "    # Method 1: Balanced - Inverse Frequency\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "    # This is impure function for now\n",
    "    loss = loss_fn(logits, labels)\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e49840",
   "metadata": {},
   "source": [
    "### Initialize and Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cd8e4dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10704\n",
      "5363\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59b595b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6690' max='6690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6690/6690 41:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.017600</td>\n",
       "      <td>0.909827</td>\n",
       "      <td>0.615141</td>\n",
       "      <td>0.629001</td>\n",
       "      <td>0.691264</td>\n",
       "      <td>0.615141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.919300</td>\n",
       "      <td>0.928607</td>\n",
       "      <td>0.599478</td>\n",
       "      <td>0.648868</td>\n",
       "      <td>0.750580</td>\n",
       "      <td>0.599478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.767400</td>\n",
       "      <td>0.707694</td>\n",
       "      <td>0.716017</td>\n",
       "      <td>0.728436</td>\n",
       "      <td>0.745427</td>\n",
       "      <td>0.716017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.529800</td>\n",
       "      <td>0.821412</td>\n",
       "      <td>0.699422</td>\n",
       "      <td>0.716486</td>\n",
       "      <td>0.748392</td>\n",
       "      <td>0.699422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.519000</td>\n",
       "      <td>1.024353</td>\n",
       "      <td>0.624650</td>\n",
       "      <td>0.677492</td>\n",
       "      <td>0.779201</td>\n",
       "      <td>0.624650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.369500</td>\n",
       "      <td>1.162384</td>\n",
       "      <td>0.694947</td>\n",
       "      <td>0.717750</td>\n",
       "      <td>0.751558</td>\n",
       "      <td>0.694947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.422600</td>\n",
       "      <td>1.045302</td>\n",
       "      <td>0.723849</td>\n",
       "      <td>0.728045</td>\n",
       "      <td>0.736437</td>\n",
       "      <td>0.723849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.329900</td>\n",
       "      <td>1.089929</td>\n",
       "      <td>0.729629</td>\n",
       "      <td>0.735666</td>\n",
       "      <td>0.742561</td>\n",
       "      <td>0.729629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>1.613433</td>\n",
       "      <td>0.692150</td>\n",
       "      <td>0.705076</td>\n",
       "      <td>0.741069</td>\n",
       "      <td>0.692150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>1.608569</td>\n",
       "      <td>0.706694</td>\n",
       "      <td>0.719924</td>\n",
       "      <td>0.742852</td>\n",
       "      <td>0.706694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>1.671465</td>\n",
       "      <td>0.721425</td>\n",
       "      <td>0.731522</td>\n",
       "      <td>0.745435</td>\n",
       "      <td>0.721425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>2.076091</td>\n",
       "      <td>0.683946</td>\n",
       "      <td>0.705353</td>\n",
       "      <td>0.746626</td>\n",
       "      <td>0.683946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>1.769991</td>\n",
       "      <td>0.717509</td>\n",
       "      <td>0.727497</td>\n",
       "      <td>0.742786</td>\n",
       "      <td>0.717509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    compute_loss_func=custom_weighted_loss_fn if FileConfig.CustomLossFn else None,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "if FileConfig.ToBuild:\n",
    "    trainer.train()\n",
    "    # Save the model\n",
    "    trainer.save_model(out_path) # Where to save model weights and config\n",
    "    tokenizer.save_pretrained(out_path) # for tokenizer stuff\n",
    "    print(\"Model saved!\")\n",
    "    print(\"Cleaning up Checkpoints...\")\n",
    "    checkpoint_dirs = glob.glob(f\"{out_path}/checkpoint-*\")\n",
    "    for checkpoint_dir in checkpoint_dirs:\n",
    "        shutil.rmtree(checkpoint_dir)\n",
    "    print(\"Clean up complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4613dcc8",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "This is kind of the manual process I suppose for the time being."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac0fe1",
   "metadata": {},
   "source": [
    "### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0e41e3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "# Load your fine-tuned model\n",
    "# TODO: UPDATE!!!\n",
    "the_judge = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=str(out_path),\n",
    "    tokenizer=str(out_path),\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed64475",
   "metadata": {},
   "source": [
    "Making up some claims and support for manual testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "547d7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_test_data = [\n",
    "    # SUPPORTS - 4 claims\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"claim\": \"The 2024 US presidential election had the highest voter turnout in history.\",\n",
    "        \"evidence\": [\n",
    "            \"According to the Federal Election Commission, approximately 158 million Americans voted in the 2024 presidential election. This surpassed the previous record of 155 million voters set in 2020. Election officials reported that turnout reached 66.8% of eligible voters, marking a new milestone in American electoral participation.\",\n",
    "        ],\n",
    "        \"label\": \"SUPPORTS\",\n",
    "        \"context\": \"Short and factual about voter turnout.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2, \n",
    "        \"claim\": \"Social Security benefits increased by 3.2% in 2024.\",\n",
    "        \"evidence\": [\n",
    "            \"The Social Security Administration announced a 3.2% cost-of-living adjustment for 2024 benefits. This increase affects over 67 million Social Security beneficiaries and 7 million SSI recipients. The adjustment was based on the Consumer Price Index data from the third quarter of 2023.\",\n",
    "        ],\n",
    "        \"label\": \"SUPPORTS\",\n",
    "        \"context\": \"Matching percentages.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"claim\": \"The federal minimum wage in America is $7.25 per hour.\",\n",
    "        \"evidence\": [\n",
    "            \"The federal minimum wage has remained at $7.25 per hour since July 2009, when it was last increased under the Fair Minimum Wage Act. While many states have implemented higher minimum wages, the federal rate serves as the baseline for all states. Congressional attempts to raise the federal minimum wage to $15 per hour have stalled in recent legislative sessions.\",\n",
    "        ],\n",
    "        \"label\": \"SUPPORTS\",\n",
    "        \"context\": \"Simple fact about minimum wage.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"claim\": \"Medicare covers prescription drug costs for seniors.\",\n",
    "        \"evidence\": [\n",
    "            \"Medicare Part D provides prescription drug coverage for Medicare beneficiaries, covering approximately 63 million seniors and disabled individuals. The program was established in 2006 and helps reduce out-of-pocket prescription costs. Recent legislation has also capped annual prescription drug costs at $2,000 starting in 2025 for Medicare recipients.\",\n",
    "        ],\n",
    "        \"label\": \"SUPPORTS\",\n",
    "        \"context\": \"More evidence for slightly more vague claim.\"\n",
    "    },\n",
    "    # REFUTES - 4 claims  \n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"claim\": \"The US Constitution requires congressional approval for all military deployments overseas.\",\n",
    "        \"evidence\": [\n",
    "            \"The Constitution grants Congress the power to declare war, but does not require congressional approval for all military actions. The President, as Commander in Chief, has authority to deploy troops for limited periods without congressional authorization. The War Powers Resolution of 1973 requires congressional approval only for deployments lasting more than 60 days.\",\n",
    "        ],\n",
    "        \"label\": \"REFUTES\",\n",
    "        \"context\": \"A constitutional misconception.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 6,\n",
    "        \"claim\": \"Climate change legislation was passed by Congress in 2023 with bipartisan support.\",\n",
    "        \"evidence\": [\n",
    "            \"No major climate change legislation received bipartisan support in Congress during 2023. The Inflation Reduction Act, which included climate provisions, was passed in 2022 with only Democratic votes. Several climate-related bills were introduced in 2023 but failed to advance due to partisan disagreements over implementation and funding mechanisms.\",\n",
    "        ],\n",
    "        \"label\": \"REFUTES\",\n",
    "        \"context\": \"A false bipartisan claim about climate legislation.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 7,\n",
    "        \"claim\": \"The federal deficit decreased by 50% in 2024.\",\n",
    "        \"evidence\": [\n",
    "            \"The Congressional Budget Office reported that the federal deficit increased by approximately 8% in fiscal year 2024, reaching $1.9 trillion. This represents a significant increase from the previous year's deficit of $1.7 trillion. Rising interest payments on national debt and increased government spending contributed to the larger deficit.\",\n",
    "        ],\n",
    "        \"label\": \"REFUTES\",\n",
    "        \"context\": \"A favourite for some, incorrect percentages.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 8,\n",
    "        \"claim\": \"All Supreme Court justices must be confirmed by a two-thirds majority in the Senate.\",\n",
    "        \"evidence\": [\n",
    "            \"Supreme Court nominees require only a simple majority vote for confirmation in the Senate, not a two-thirds majority. This threshold was established by Senate rules and precedent. The confirmation process involves Senate Judiciary Committee hearings followed by a full Senate vote, where 51 votes are sufficient for confirmation.\",\n",
    "        ],\n",
    "        \"label\": \"REFUTES\",\n",
    "        \"context\": \"Incorrect claim about voting threshold.\"\n",
    "    },\n",
    "    # NOT ENOUGH INFO - 2 claims\n",
    "    {\n",
    "        \"id\": 9,\n",
    "        \"claim\": \"The new infrastructure bill will create 500,000 jobs in rural communities specifically.\",\n",
    "        \"evidence\": [\n",
    "            \"The Infrastructure Investment and Jobs Act allocated $1.2 trillion for various infrastructure projects across the United States. The legislation includes funding for roads, bridges, broadband expansion, and water systems. Economic analysts project the bill will create millions of jobs nationwide over the next decade, with significant benefits expected for both urban and rural areas.\",\n",
    "        ],\n",
    "        \"label\": \"NOT ENOUGH INFO\",\n",
    "        \"context\": \"Evidence is about the project but without the supporting figures.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 10,\n",
    "        \"claim\": \"Congressional approval ratings reached their lowest point since 1974 last month.\",\n",
    "        \"evidence\": [\n",
    "            \"Recent polling shows Congress has historically low approval ratings, with multiple surveys indicating public dissatisfaction with legislative performance. Gallup polling has tracked congressional approval since the 1970s, showing significant fluctuations over the decades. Political polarization and gridlock have contributed to declining public confidence in the institution.\",\n",
    "        ],\n",
    "        \"label\": \"NOT ENOUGH INFO\",\n",
    "        \"context\": \"Evidence does not specify exact timeframe nor comparison to 1974.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 11,\n",
    "        \"claim\": \"Trump and Putin are meeting in Alaska to talk about ending the war in Ukraine.\",\n",
    "        \"evidence\": [],\n",
    "        \"label\": \"NOT ENOUGH INFO\",\n",
    "        \"context\": \"Very recent news as of today, withholding evidence even though it does techincally exist.\"\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426c3350",
   "metadata": {},
   "source": [
    "Above: I was going to do the multiple sentences but when we pass data into the model I zip them up anyways so... it's half done for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "71771094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Summary:\n",
      "Total samples: 11\n",
      "\n",
      "Label Distribution:\n",
      "SUPPORTS: 4\n",
      "REFUTES: 4\n",
      "NOT ENOUGH INFO: 3\n",
      "\n",
      "Claim Length Statistics:\n",
      "Average claim length: 71 characters\n",
      "Shortest claim: 45 characters\n",
      "Longest claim: 90 characters\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame and Dataset\n",
    "def create_fake_dataset():\n",
    "    \"\"\"Create fake dataset for testing judge model\"\"\"\n",
    "    df = pd.DataFrame(fake_test_data)\n",
    "    \n",
    "    print(\"Test Dataset Summary:\")\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    print(\"\\nLabel Distribution:\")\n",
    "    label_counts = df['label'].value_counts()\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"{label}: {count}\")\n",
    "    \n",
    "    print(\"\\nClaim Length Statistics:\")\n",
    "    df['claim_length'] = df['claim'].str.len()\n",
    "    print(f\"Average claim length: {df['claim_length'].mean():.0f} characters\")\n",
    "    print(f\"Shortest claim: {df['claim_length'].min()} characters\")\n",
    "    print(f\"Longest claim: {df['claim_length'].max()} characters\")\n",
    "    \n",
    "    return Dataset.from_pandas(df)\n",
    "\n",
    "# Create the dataset\n",
    "test_dataset = create_fake_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d50022e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST CASE: 01\n",
      "Claim: The 2024 US presidential election had the highest voter turnout in history.\n",
      "Evidence: \n",
      "  According to the Federal Election Commission, approximately 158 million Americans voted in the 2024 presidential election. This surpassed the previous record of 155 million voters set in 2020. Election officials reported that turnout reached 66.8% of eligible voters, marking a new milestone in American electoral participation.\n",
      "Label: SUPPORTS\n",
      "ABOUT: Short and factual about voter turnout.\n",
      "RESULT: {\n",
      "  \"label\": \"LABEL_0\",\n",
      "  \"score\": 0.9166038632392883\n",
      "}\n",
      "\n",
      "✅ PREDICTED: SUPPORTS | ACTUAL: SUPPORTS\n",
      "\n",
      "TEST CASE: 02\n",
      "Claim: Social Security benefits increased by 3.2% in 2024.\n",
      "Evidence: \n",
      "  The Social Security Administration announced a 3.2% cost-of-living adjustment for 2024 benefits. This increase affects over 67 million Social Security beneficiaries and 7 million SSI recipients. The adjustment was based on the Consumer Price Index data from the third quarter of 2023.\n",
      "Label: SUPPORTS\n",
      "ABOUT: Matching percentages.\n",
      "RESULT: {\n",
      "  \"label\": \"LABEL_0\",\n",
      "  \"score\": 0.9789601564407349\n",
      "}\n",
      "\n",
      "✅ PREDICTED: SUPPORTS | ACTUAL: SUPPORTS\n",
      "\n",
      "TEST CASE: 03\n",
      "Claim: The federal minimum wage in America is $7.25 per hour.\n",
      "Evidence: \n",
      "  The federal minimum wage has remained at $7.25 per hour since July 2009, when it was last increased under the Fair Minimum Wage Act. While many states have implemented higher minimum wages, the federal rate serves as the baseline for all states. Congressional attempts to raise the federal minimum wage to $15 per hour have stalled in recent legislative sessions.\n",
      "Label: SUPPORTS\n",
      "ABOUT: Simple fact about minimum wage.\n",
      "RESULT: {\n",
      "  \"label\": \"LABEL_2\",\n",
      "  \"score\": 0.9769569039344788\n",
      "}\n",
      "\n",
      "❌ PREDICTED: NOT ENOUGH INFO | ACTUAL: SUPPORTS\n",
      "\n",
      "TEST CASE: 04\n",
      "Claim: Medicare covers prescription drug costs for seniors.\n",
      "Evidence: \n",
      "  Medicare Part D provides prescription drug coverage for Medicare beneficiaries, covering approximately 63 million seniors and disabled individuals. The program was established in 2006 and helps reduce out-of-pocket prescription costs. Recent legislation has also capped annual prescription drug costs at $2,000 starting in 2025 for Medicare recipients.\n",
      "Label: SUPPORTS\n",
      "ABOUT: More evidence for slightly more vague claim.\n",
      "RESULT: {\n",
      "  \"label\": \"LABEL_0\",\n",
      "  \"score\": 0.9810014367103577\n",
      "}\n",
      "\n",
      "✅ PREDICTED: SUPPORTS | ACTUAL: SUPPORTS\n",
      "\n",
      "TEST CASE: 05\n",
      "Claim: The US Constitution requires congressional approval for all military deployments overseas.\n",
      "Evidence: \n",
      "  The Constitution grants Congress the power to declare war, but does not require congressional approval for all military actions. The President, as Commander in Chief, has authority to deploy troops for limited periods without congressional authorization. The War Powers Resolution of 1973 requires congressional approval only for deployments lasting more than 60 days.\n",
      "Label: REFUTES\n",
      "ABOUT: A constitutional misconception.\n",
      "RESULT: {\n",
      "  \"label\": \"LABEL_0\",\n",
      "  \"score\": 0.936375617980957\n",
      "}\n",
      "\n",
      "❌ PREDICTED: SUPPORTS | ACTUAL: REFUTES\n",
      "\n",
      "TEST CASE: 06\n",
      "Claim: Climate change legislation was passed by Congress in 2023 with bipartisan support.\n",
      "Evidence: \n",
      "  No major climate change legislation received bipartisan support in Congress during 2023. The Inflation Reduction Act, which included climate provisions, was passed in 2022 with only Democratic votes. Several climate-related bills were introduced in 2023 but failed to advance due to partisan disagreements over implementation and funding mechanisms.\n",
      "Label: REFUTES\n",
      "ABOUT: A false bipartisan claim about climate legislation.\n",
      "RESULT: {\n",
      "  \"label\": \"LABEL_0\",\n",
      "  \"score\": 0.9306058883666992\n",
      "}\n",
      "\n",
      "❌ PREDICTED: SUPPORTS | ACTUAL: REFUTES\n",
      "\n",
      "TEST CASE: 07\n",
      "Claim: The federal deficit decreased by 50% in 2024.\n",
      "Evidence: \n",
      "  The Congressional Budget Office reported that the federal deficit increased by approximately 8% in fiscal year 2024, reaching $1.9 trillion. This represents a significant increase from the previous year's deficit of $1.7 trillion. Rising interest payments on national debt and increased government spending contributed to the larger deficit.\n",
      "Label: REFUTES\n",
      "ABOUT: A favourite for some, incorrect percentages.\n",
      "RESULT: {\n",
      "  \"label\": \"LABEL_2\",\n",
      "  \"score\": 0.9134212732315063\n",
      "}\n",
      "\n",
      "❌ PREDICTED: NOT ENOUGH INFO | ACTUAL: REFUTES\n",
      "\n",
      "TEST CASE: 08\n",
      "Claim: All Supreme Court justices must be confirmed by a two-thirds majority in the Senate.\n",
      "Evidence: \n",
      "  Supreme Court nominees require only a simple majority vote for confirmation in the Senate, not a two-thirds majority. This threshold was established by Senate rules and precedent. The confirmation process involves Senate Judiciary Committee hearings followed by a full Senate vote, where 51 votes are sufficient for confirmation.\n",
      "Label: REFUTES\n",
      "ABOUT: Incorrect claim about voting threshold.\n",
      "RESULT: {\n",
      "  \"label\": \"LABEL_2\",\n",
      "  \"score\": 0.9924492835998535\n",
      "}\n",
      "\n",
      "❌ PREDICTED: NOT ENOUGH INFO | ACTUAL: REFUTES\n",
      "\n",
      "TEST CASE: 09\n",
      "Claim: The new infrastructure bill will create 500,000 jobs in rural communities specifically.\n",
      "Evidence: \n",
      "  The Infrastructure Investment and Jobs Act allocated $1.2 trillion for various infrastructure projects across the United States. The legislation includes funding for roads, bridges, broadband expansion, and water systems. Economic analysts project the bill will create millions of jobs nationwide over the next decade, with significant benefits expected for both urban and rural areas.\n",
      "Label: NOT ENOUGH INFO\n",
      "ABOUT: Evidence is about the project but without the supporting figures.\n",
      "RESULT: {\n",
      "  \"label\": \"LABEL_2\",\n",
      "  \"score\": 0.9376926422119141\n",
      "}\n",
      "\n",
      "✅ PREDICTED: NOT ENOUGH INFO | ACTUAL: NOT ENOUGH INFO\n",
      "\n",
      "TEST CASE: 10\n",
      "Claim: Congressional approval ratings reached their lowest point since 1974 last month.\n",
      "Evidence: \n",
      "  Recent polling shows Congress has historically low approval ratings, with multiple surveys indicating public dissatisfaction with legislative performance. Gallup polling has tracked congressional approval since the 1970s, showing significant fluctuations over the decades. Political polarization and gridlock have contributed to declining public confidence in the institution.\n",
      "Label: NOT ENOUGH INFO\n",
      "ABOUT: Evidence does not specify exact timeframe nor comparison to 1974.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT: {\n",
      "  \"label\": \"LABEL_2\",\n",
      "  \"score\": 0.6960554718971252\n",
      "}\n",
      "\n",
      "✅ PREDICTED: NOT ENOUGH INFO | ACTUAL: NOT ENOUGH INFO\n",
      "\n",
      "TEST CASE: 11\n",
      "Claim: Trump and Putin are meeting in Alaska to talk about ending the war in Ukraine.\n",
      "Evidence: \n",
      "Label: NOT ENOUGH INFO\n",
      "ABOUT: Very recent news as of today, withholding evidence even though it does techincally exist.\n",
      "RESULT: {\n",
      "  \"label\": \"LABEL_1\",\n",
      "  \"score\": 0.9951300621032715\n",
      "}\n",
      "\n",
      "❌ PREDICTED: REFUTES | ACTUAL: NOT ENOUGH INFO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each test_case\n",
    "for tc in test_dataset:\n",
    "    print(f\"TEST CASE: {tc['id']:02}\")\n",
    "    print(f\"Claim: {tc['claim']}\")\n",
    "    print(f\"Evidence: \")\n",
    "    for x in [y for y in tc['evidence']]:\n",
    "        print(f\"  {x}\")\n",
    "    expected = tc['label']\n",
    "    print(f\"Label: {expected}\")\n",
    "    print(f\"ABOUT: {tc['context']}\")\n",
    "    fixed = data_transform(tc['claim'], tc['evidence'])\n",
    "    result_list = the_judge(fixed)\n",
    "    result = result_list[0]\n",
    "    print(\"RESULT:\", json.dumps(result, indent=2))\n",
    "    actual = result.get('label')\n",
    "    if \"0\" in actual:\n",
    "        actual = \"SUPPORTS\"\n",
    "    elif \"1\" in actual:\n",
    "        actual = \"REFUTES\"\n",
    "    elif \"2\" in actual:\n",
    "        actual = \"NOT ENOUGH INFO\"\n",
    "    else:\n",
    "        actual = \"ERROR - WHAT?!?\"\n",
    "    print()\n",
    "    correct = actual == expected\n",
    "    if correct:\n",
    "        print(f\"✅ PREDICTED: {actual} | ACTUAL: {tc['label']}\")\n",
    "    else:\n",
    "        print(f\"❌ PREDICTED: {actual} | ACTUAL: {tc['label']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db0b54b",
   "metadata": {},
   "source": [
    "I know the validation data shouldn't be used, but just checking here for fun..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "64e6bf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"accuracy\": 0.6145833333333334,\n",
      "  \"f1\": 0.5873959778635663,\n",
      "  \"precision\": 0.6221580366647493,\n",
      "  \"recall\": 0.6145833333333334\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "t_preds = []\n",
    "t_labels = []\n",
    "min_n = min(pdfd['label'].value_counts())\n",
    "pdfs = pd.concat([\n",
    "        pdfd[pdfd['label'] == 'SUPPORTS'].sample(n=min_n, replace=False, ignore_index=True),\n",
    "        pdfd[pdfd['label'] == 'REFUTES'].sample(n=min_n, replace=False, ignore_index=True),\n",
    "        pdfd[pdfd['label'] == 'NOT ENOUGH INFO'].sample(frac=1, replace=False, ignore_index=True),\n",
    "    ])\n",
    "for _, row in pdfs.iterrows():\n",
    "    fixed = data_transform(row['claim'], row['evidence'])\n",
    "    result_list = the_judge(fixed)\n",
    "    result = result_list[0]\n",
    "    actual = result.get('label')\n",
    "    expected = row['label']\n",
    "    if \"0\" in actual:\n",
    "        actual = \"SUPPORTS\"\n",
    "    elif \"1\" in actual:\n",
    "        actual = \"REFUTES\"\n",
    "    elif \"2\" in actual:\n",
    "        actual = \"NOT ENOUGH INFO\"\n",
    "    else:\n",
    "        actual = \"ERROR - WHAT?!?\"\n",
    "    t_preds.append(actual)\n",
    "    t_labels.append(expected)\n",
    "\n",
    "def compute_metrics_simple(predicted_values: List[str], actual_values: List[str]):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        actual_values, predicted_values, average='weighted'\n",
    "    )\n",
    "    accuracy = accuracy_score(actual_values, predicted_values)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "test_results = compute_metrics_simple(t_preds, t_labels)\n",
    "print(json.dumps(test_results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fa2d494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "SUPPORTS           416\n",
      "REFUTES            416\n",
      "NOT ENOUGH INFO    416\n",
      "Name: count, dtype: int64\n",
      "\n",
      "1248\n",
      "\n",
      "{\n",
      "  \"SUPPORTS\": {\n",
      "    \"SUPPORTS\": 334,\n",
      "    \"REFUTES\": 74,\n",
      "    \"NOT ENOUGH INFO\": 146\n",
      "  },\n",
      "  \"REFUTES\": {\n",
      "    \"SUPPORTS\": 45,\n",
      "    \"REFUTES\": 315,\n",
      "    \"NOT ENOUGH INFO\": 152\n",
      "  },\n",
      "  \"NOT ENOUGH INFO\": {\n",
      "    \"SUPPORTS\": 37,\n",
      "    \"REFUTES\": 27,\n",
      "    \"NOT ENOUGH INFO\": 118\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(pdfs['label'].value_counts())\n",
    "print()\n",
    "print(len(t_preds))\n",
    "print()\n",
    "mycounts = {}\n",
    "for exp, act in zip(t_preds, t_labels):\n",
    "    try:\n",
    "        mycounts[exp][act] += 1\n",
    "    except:\n",
    "        one = mycounts.get(exp)\n",
    "        if one is None:\n",
    "            mycounts[exp] = {}\n",
    "        mycounts[exp][act] = 1\n",
    "\n",
    "print(json.dumps(mycounts, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0240c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
