{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb4a4f8-6852-4470-8c79-b836c8477b90",
   "metadata": {},
   "source": [
    "# Statement Classifier\n",
    "\n",
    "This project's goal is to train a model that can determine if a statement is either a claim that can be fact-checked, or some other statement like an opinion that cannot be fact checked. \n",
    "\n",
    "## TODO:\n",
    "\n",
    "- [ ] Before training again, setup file structure for saving the 'latest' model, and moving them back into time-stamped dirs, either save some metadata file or something. \n",
    "- [ ] Config at top to control what runs when you click GO.\n",
    "- [ ] function-ize processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06276f02-8227-4961-926d-68698649d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bf0ab65-e839-4280-8385-abb016969d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ksull18/code/iu-autonomous-fact-checker/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ecb714a-dd3c-4522-a851-08f102d32b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "cell": {
        "!": "OSMagics",
        "HTML": "Other",
        "SVG": "Other",
        "bash": "Other",
        "capture": "ExecutionMagics",
        "code_wrap": "ExecutionMagics",
        "debug": "ExecutionMagics",
        "file": "Other",
        "html": "DisplayMagics",
        "javascript": "DisplayMagics",
        "js": "DisplayMagics",
        "latex": "DisplayMagics",
        "markdown": "DisplayMagics",
        "perl": "Other",
        "prun": "ExecutionMagics",
        "pypy": "Other",
        "python": "Other",
        "python2": "Other",
        "python3": "Other",
        "ruby": "Other",
        "script": "ScriptMagics",
        "sh": "Other",
        "svg": "DisplayMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "writefile": "OSMagics"
       },
       "line": {
        "alias": "OSMagics",
        "alias_magic": "BasicMagics",
        "autoawait": "AsyncMagics",
        "autocall": "AutoMagics",
        "automagic": "AutoMagics",
        "autosave": "KernelMagics",
        "bookmark": "OSMagics",
        "cat": "Other",
        "cd": "OSMagics",
        "clear": "KernelMagics",
        "code_wrap": "ExecutionMagics",
        "colors": "BasicMagics",
        "conda": "PackagingMagics",
        "config": "ConfigMagics",
        "connect_info": "KernelMagics",
        "cp": "Other",
        "debug": "ExecutionMagics",
        "dhist": "OSMagics",
        "dirs": "OSMagics",
        "doctest_mode": "BasicMagics",
        "ed": "Other",
        "edit": "KernelMagics",
        "env": "OSMagics",
        "gui": "BasicMagics",
        "hist": "Other",
        "history": "HistoryMagics",
        "killbgscripts": "ScriptMagics",
        "ldir": "Other",
        "less": "KernelMagics",
        "lf": "Other",
        "lk": "Other",
        "ll": "Other",
        "load": "CodeMagics",
        "load_ext": "ExtensionMagics",
        "loadpy": "CodeMagics",
        "logoff": "LoggingMagics",
        "logon": "LoggingMagics",
        "logstart": "LoggingMagics",
        "logstate": "LoggingMagics",
        "logstop": "LoggingMagics",
        "ls": "Other",
        "lsmagic": "BasicMagics",
        "lx": "Other",
        "macro": "ExecutionMagics",
        "magic": "BasicMagics",
        "mamba": "PackagingMagics",
        "man": "KernelMagics",
        "matplotlib": "PylabMagics",
        "micromamba": "PackagingMagics",
        "mkdir": "Other",
        "more": "KernelMagics",
        "mv": "Other",
        "notebook": "BasicMagics",
        "page": "BasicMagics",
        "pastebin": "CodeMagics",
        "pdb": "ExecutionMagics",
        "pdef": "NamespaceMagics",
        "pdoc": "NamespaceMagics",
        "pfile": "NamespaceMagics",
        "pinfo": "NamespaceMagics",
        "pinfo2": "NamespaceMagics",
        "pip": "PackagingMagics",
        "popd": "OSMagics",
        "pprint": "BasicMagics",
        "precision": "BasicMagics",
        "prun": "ExecutionMagics",
        "psearch": "NamespaceMagics",
        "psource": "NamespaceMagics",
        "pushd": "OSMagics",
        "pwd": "OSMagics",
        "pycat": "OSMagics",
        "pylab": "PylabMagics",
        "qtconsole": "KernelMagics",
        "quickref": "BasicMagics",
        "recall": "HistoryMagics",
        "rehashx": "OSMagics",
        "reload_ext": "ExtensionMagics",
        "rep": "Other",
        "rerun": "HistoryMagics",
        "reset": "NamespaceMagics",
        "reset_selective": "NamespaceMagics",
        "rm": "Other",
        "rmdir": "Other",
        "run": "ExecutionMagics",
        "save": "CodeMagics",
        "sc": "OSMagics",
        "set_env": "OSMagics",
        "store": "StoreMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "tb": "ExecutionMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "unalias": "OSMagics",
        "unload_ext": "ExtensionMagics",
        "uv": "PackagingMagics",
        "who": "NamespaceMagics",
        "who_ls": "NamespaceMagics",
        "whos": "NamespaceMagics",
        "xdel": "NamespaceMagics",
        "xmode": "BasicMagics"
       }
      },
      "text/plain": [
       "Available line magics:\n",
       "%alias  %alias_magic  %autoawait  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %code_wrap  %colors  %conda  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %mamba  %man  %matplotlib  %micromamba  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %uv  %who  %who_ls  %whos  %xdel  %xmode\n",
       "\n",
       "Available cell magics:\n",
       "%%!  %%HTML  %%SVG  %%bash  %%capture  %%code_wrap  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
       "\n",
       "Automagic is ON, % prefix IS NOT needed for line magics."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "099785cc-6380-4a5a-848f-1ad363d1a3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715da55e-e7f7-4eb2-8932-3953fb368d85",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec527565-22e2-44c0-b0c6-813108d0d6ce",
   "metadata": {},
   "source": [
    "### Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6095431b-d47a-4e5b-87a1-d8c72163de80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker_title</th>\n",
       "      <th>Speaker_party</th>\n",
       "      <th>Speaker_role</th>\n",
       "      <th>File_id</th>\n",
       "      <th>Length</th>\n",
       "      <th>Line_number</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>September 25, 1988</td>\n",
       "      <td>Information</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The First Bush-Dukakis Presidential Debate</td>\n",
       "      <td>Information</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Good evening.</td>\n",
       "      <td>Jim Lehrer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderator</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.343189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>On behalf of the Commission on Presidential De...</td>\n",
       "      <td>Jim Lehrer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderator</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0.810043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I'm Jim Lehrer of the McNeil-Lehrer News Hour.</td>\n",
       "      <td>Jim Lehrer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderator</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_id                                               Text  \\\n",
       "0            1                                 September 25, 1988   \n",
       "1            2         The First Bush-Dukakis Presidential Debate   \n",
       "2            3                                      Good evening.   \n",
       "3            4  On behalf of the Commission on Presidential De...   \n",
       "4            5     I'm Jim Lehrer of the McNeil-Lehrer News Hour.   \n",
       "\n",
       "       Speaker Speaker_title Speaker_party Speaker_role         File_id  \\\n",
       "0  Information           NaN           NaN          NaN  1988-09-25.txt   \n",
       "1  Information           NaN           NaN          NaN  1988-09-25.txt   \n",
       "2   Jim Lehrer           NaN           NaN    Moderator  1988-09-25.txt   \n",
       "3   Jim Lehrer           NaN           NaN    Moderator  1988-09-25.txt   \n",
       "4   Jim Lehrer           NaN           NaN    Moderator  1988-09-25.txt   \n",
       "\n",
       "   Length  Line_number  Sentiment  \n",
       "0       3            1        NaN  \n",
       "1       5            2   0.000000  \n",
       "2       2            3   0.343189  \n",
       "3      23            4   0.810043  \n",
       "4       8            5   0.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "here = Path().cwd()\n",
    "cbdata_path = here / \".data_sets\" / \"ClaimBuster_Datasets\" / \"datasets\" # ClaimBuster data location\n",
    "all_sentences_csv_path = cbdata_path / \"all_sentences.csv\"\n",
    "if not all_sentences_csv_path.exists():\n",
    "    raise Exception()\n",
    "all_sent_df = pd.read_csv(all_sentences_csv_path)\n",
    "all_sent_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acc45bfb-c2c7-4b29-be49-8328f86b9a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker_title</th>\n",
       "      <th>Speaker_party</th>\n",
       "      <th>File_id</th>\n",
       "      <th>Length</th>\n",
       "      <th>Line_number</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>I think we've seen a deterioration of values.</td>\n",
       "      <td>George Bush</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>I think for a while as a nation we condoned th...</td>\n",
       "      <td>George Bush</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.456018</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>For a while, as I recall, it even seems to me ...</td>\n",
       "      <td>George Bush</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.805547</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>So we've seen a deterioration in values, and o...</td>\n",
       "      <td>George Bush</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>0.698942</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>We got away, we got into this feeling that val...</td>\n",
       "      <td>George Bush</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_id                                               Text  \\\n",
       "0           16      I think we've seen a deterioration of values.   \n",
       "1           17  I think for a while as a nation we condoned th...   \n",
       "2           18  For a while, as I recall, it even seems to me ...   \n",
       "3           19  So we've seen a deterioration in values, and o...   \n",
       "4           20  We got away, we got into this feeling that val...   \n",
       "\n",
       "       Speaker   Speaker_title Speaker_party         File_id  Length  \\\n",
       "0  George Bush  Vice President    REPUBLICAN  1988-09-25.txt       8   \n",
       "1  George Bush  Vice President    REPUBLICAN  1988-09-25.txt      16   \n",
       "2  George Bush  Vice President    REPUBLICAN  1988-09-25.txt      29   \n",
       "3  George Bush  Vice President    REPUBLICAN  1988-09-25.txt      35   \n",
       "4  George Bush  Vice President    REPUBLICAN  1988-09-25.txt      15   \n",
       "\n",
       "   Line_number  Sentiment  Verdict  \n",
       "0           16   0.000000       -1  \n",
       "1           17  -0.456018       -1  \n",
       "2           18  -0.805547       -1  \n",
       "3           19   0.698942       -1  \n",
       "4           20   0.000000       -1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowdsourced_path = cbdata_path / \"crowdsourced.csv\"\n",
    "if not crowdsourced_path.exists():\n",
    "    raise Exception()\n",
    "crowdsourced_df = pd.read_csv(crowdsourced_path)\n",
    "crowdsourced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bdf3de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker_title</th>\n",
       "      <th>Speaker_party</th>\n",
       "      <th>File_id</th>\n",
       "      <th>Length</th>\n",
       "      <th>Line_number</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>You know, I saw a movie - \"Crocodile Dundee.\"</td>\n",
       "      <td>George Bush</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>We're consuming 50 percent of the world's coca...</td>\n",
       "      <td>Michael Dukakis</td>\n",
       "      <td>Governor</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129</td>\n",
       "      <td>That answer was about as clear as Boston harbor.</td>\n",
       "      <td>George Bush</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>9</td>\n",
       "      <td>129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131</td>\n",
       "      <td>Let me help the governor.</td>\n",
       "      <td>George Bush</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>5</td>\n",
       "      <td>131</td>\n",
       "      <td>0.212987</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172</td>\n",
       "      <td>We've run up more debt in the last eight years...</td>\n",
       "      <td>Michael Dukakis</td>\n",
       "      <td>Governor</td>\n",
       "      <td>DEMOCRAT</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>22</td>\n",
       "      <td>172</td>\n",
       "      <td>-0.268506</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_id                                               Text  \\\n",
       "0           26      You know, I saw a movie - \"Crocodile Dundee.\"   \n",
       "1           80  We're consuming 50 percent of the world's coca...   \n",
       "2          129   That answer was about as clear as Boston harbor.   \n",
       "3          131                          Let me help the governor.   \n",
       "4          172  We've run up more debt in the last eight years...   \n",
       "\n",
       "           Speaker   Speaker_title Speaker_party         File_id  Length  \\\n",
       "0      George Bush  Vice President    REPUBLICAN  1988-09-25.txt       9   \n",
       "1  Michael Dukakis        Governor      DEMOCRAT  1988-09-25.txt       8   \n",
       "2      George Bush  Vice President    REPUBLICAN  1988-09-25.txt       9   \n",
       "3      George Bush  Vice President    REPUBLICAN  1988-09-25.txt       5   \n",
       "4  Michael Dukakis        Governor      DEMOCRAT  1988-09-25.txt      22   \n",
       "\n",
       "   Line_number  Sentiment  Verdict  \n",
       "0           26   0.000000        0  \n",
       "1           80  -0.740979        1  \n",
       "2          129   0.000000       -1  \n",
       "3          131   0.212987       -1  \n",
       "4          172  -0.268506        1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth_path = cbdata_path / \"groundtruth.csv\"\n",
    "if not groundtruth_path.exists():\n",
    "    raise Exception()\n",
    "groundtruth_df = pd.read_csv(groundtruth_path)\n",
    "groundtruth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "140c8b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_df = pd.concat([crowdsourced_df, groundtruth_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdd8b7ce-f4ee-45c3-9fd3-6775f7f7a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    # Factual claims (label = 1)\n",
    "    (\"John Smith was elected mayor in 2020\", 1),\n",
    "    (\"The company reported $2 million in revenue\", 1),\n",
    "    (\"She graduated from Harvard University\", 1),\n",
    "    (\"The meeting was scheduled for 3 PM\", 1),\n",
    "    (\"COVID-19 cases increased by 15% last month\", 1),\n",
    "    # Opinions (label = 0)\n",
    "    (\"This is the best restaurant in town\", 0),\n",
    "    (\"We should invest more in education\", 0),\n",
    "    (\"That movie was terrible\", 0),\n",
    "    (\"This policy is unfair to working families\", 0),\n",
    "    (\"Climate change is the most important issue\", 0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84a817c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Length</th>\n",
       "      <th>Line_number</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23533.000000</td>\n",
       "      <td>23533.000000</td>\n",
       "      <td>23533.000000</td>\n",
       "      <td>23530.000000</td>\n",
       "      <td>23533.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16860.946841</td>\n",
       "      <td>17.876386</td>\n",
       "      <td>531.862279</td>\n",
       "      <td>-0.047797</td>\n",
       "      <td>-0.414949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9576.117567</td>\n",
       "      <td>12.717837</td>\n",
       "      <td>326.215351</td>\n",
       "      <td>0.462105</td>\n",
       "      <td>0.850329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-0.978973</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8862.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>-0.420186</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16969.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24755.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>786.000000</td>\n",
       "      <td>0.274032</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34458.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>1392.000000</td>\n",
       "      <td>0.988349</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentence_id        Length   Line_number     Sentiment       Verdict\n",
       "count  23533.000000  23533.000000  23533.000000  23530.000000  23533.000000\n",
       "mean   16860.946841     17.876386    531.862279     -0.047797     -0.414949\n",
       "std     9576.117567     12.717837    326.215351      0.462105      0.850329\n",
       "min       16.000000      5.000000     12.000000     -0.978973     -1.000000\n",
       "25%     8862.000000      9.000000    258.000000     -0.420186     -1.000000\n",
       "50%    16969.000000     14.000000    495.000000      0.000000     -1.000000\n",
       "75%    24755.000000     23.000000    786.000000      0.274032      0.000000\n",
       "max    34458.000000    152.000000   1392.000000      0.988349      1.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cg_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0ee1883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- part 01 ---\n",
      "   sentence_id  label                                               text\n",
      "0        27247      1                We're 9 million jobs short of that.\n",
      "1        10766      1  You know, last year up to this time, we've los...\n",
      "2         3327      1  And in November of 1975 I was the first presid...\n",
      "3        19700      1  And what we've done during the Bush administra...\n",
      "4        12600      1  Do you know we don't have a single program spo...\n",
      "        sentence_id        label\n",
      "count   9674.000000  9674.000000\n",
      "mean   16268.353628     0.285714\n",
      "std     9388.575939     0.451777\n",
      "min       16.000000     0.000000\n",
      "25%     8344.000000     0.000000\n",
      "50%    16455.500000     0.000000\n",
      "75%    24086.250000     1.000000\n",
      "max    34458.000000     1.000000\n",
      "--- part 02 ---\n",
      "   sentence_id  label                                               text\n",
      "0        15083      1  When I made my decision to stop all trade with...\n",
      "1        16799      1  We've got the highest inflation we've had in t...\n",
      "2        32570      1  They started from that little area, and now th...\n",
      "3        17644      1  Yes, there has been an increase in poverty, bu...\n",
      "4        32512      1  And, yes, when I was a senator, I did vote to ...\n",
      "        sentence_id        label\n",
      "count   8292.000000  8292.000000\n",
      "mean   16231.974433     0.333333\n",
      "std     9412.544929     0.471433\n",
      "min       20.000000     0.000000\n",
      "25%     8379.500000     0.000000\n",
      "50%    16394.500000     0.000000\n",
      "75%    24028.250000     1.000000\n",
      "max    34458.000000     1.000000\n",
      "--- part 03 ---\n",
      "   sentence_id  label                                               text\n",
      "0         8967      1  In other words, I have seen his program costed...\n",
      "1        27385      1  Our Navy is old -- excuse me, our Navy is smal...\n",
      "2         9818      1  The unemployment, the number of people who are...\n",
      "3        16794      1  Mr. Ford uh - actually has fewer people now in...\n",
      "4        17588      1  Today it is up to about $38,000 of earnings th...\n",
      "        sentence_id         label\n",
      "count  11056.000000  11056.000000\n",
      "mean   16330.066299      0.250000\n",
      "std     9405.549195      0.433032\n",
      "min       16.000000      0.000000\n",
      "25%     8419.750000      0.000000\n",
      "50%    16491.500000      0.000000\n",
      "75%    24134.250000      0.250000\n",
      "max    34457.000000      1.000000\n"
     ]
    }
   ],
   "source": [
    "part01_path = cbdata_path / \"2.5xNCS.json\"\n",
    "\n",
    "assert part01_path.exists()\n",
    "\n",
    "part01_df = None\n",
    "\n",
    "with open(part01_path, 'r') as file:\n",
    "    part01_df = pd.read_json(file)\n",
    "\n",
    "assert part01_df is not None\n",
    "assert type(part01_df) is pd.DataFrame\n",
    "\n",
    "print(\"--- part 01 ---\")\n",
    "print(part01_df.head())\n",
    "print(part01_df.describe())\n",
    "# ---------------------------------\n",
    "part02_path = cbdata_path / \"2xNCS.json\"\n",
    "\n",
    "assert part02_path.exists()\n",
    "\n",
    "part02_df = None\n",
    "\n",
    "with open(part02_path, 'r') as file:\n",
    "    part02_df = pd.read_json(file)\n",
    "\n",
    "assert part02_df is not None\n",
    "assert type(part02_df) is pd.DataFrame\n",
    "\n",
    "print(\"--- part 02 ---\")\n",
    "print(part02_df.head())\n",
    "print(part02_df.describe())\n",
    "# ---------------------------------\n",
    "part03_path = cbdata_path / \"3xNCS.json\"\n",
    "\n",
    "assert part03_path.exists()\n",
    "\n",
    "part03_df = None\n",
    "\n",
    "with open(part03_path, 'r') as file:\n",
    "    part03_df = pd.read_json(file)\n",
    "\n",
    "assert part03_df is not None\n",
    "assert type(part03_df) is pd.DataFrame\n",
    "\n",
    "print(\"--- part 03 ---\")\n",
    "print(part03_df.head())\n",
    "print(part03_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d59e4630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sentence_id         label\n",
      "count  29022.000000  29022.000000\n",
      "mean   16281.469161      0.285714\n",
      "std     9401.659478      0.451762\n",
      "min       16.000000      0.000000\n",
      "25%     8384.500000      0.000000\n",
      "50%    16455.500000      0.000000\n",
      "75%    24089.000000      1.000000\n",
      "max    34458.000000      1.000000\n",
      "Dataset Size: 29022\n"
     ]
    }
   ],
   "source": [
    "all_parts_df = pd.concat([part01_df, part02_df, part03_df])\n",
    "print(all_parts_df.describe())\n",
    "print(f\"Dataset Size: {len(all_parts_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf2798f",
   "metadata": {},
   "source": [
    "### Additional Data Exploring\n",
    "\n",
    "After building the model and performing some manual testing, the statement, \"Barack Obama was president from 2009 to 2017,\" kept being returned as an opinion when it is actually a verifiable claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a925905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Obama mentions: 271\n",
      "Obama Claims (LABEL_1): 147\n",
      "Obama Opinions (LABEL_0): 124\n",
      "Obama Claim Percentage: 54.24354243542435%\n",
      "\n",
      "Sample Obama Entries as Claims\n",
      "--------------- Claims ---------------\n",
      "     sentence_id  label                                               text\n",
      "76          6216      1  Senator Obama, as a member of the Illinois Sta...\n",
      "162         2427      1  Right now, the CBO says up to 20 million peopl...\n",
      "217        30219      1  And my successor, John Kerry, and President Ob...\n",
      "320         3926      1  Now General Petraeus has praised the successes...\n",
      "328         5665      1  Senator Obama has asked for nearly $1 billion ...\n",
      "331         2381      1  I just don't know how the president could have...\n",
      "351        33634      1  We have, during his regime, during President O...\n",
      "408         2201      1  And ironically, if you repeal Obamacare, and I...\n",
      "560        10916      1  Senator Obama has approved storage and reproce...\n",
      "674         5970      1  By the way, when Senator Obama said he would u...\n",
      "--------------- Opinions ---------------\n",
      "      sentence_id  label                                               text\n",
      "2770        11290      0  Now, Senator Obama without precondition wants ...\n",
      "3375         4359      0    And we can't do what Senator Obama wants to do.\n",
      "3413         6247      0  Just again, the example of the eloquence of Se...\n",
      "3562         5763      0  When Senator Obama was first asked, he said, \"...\n",
      "3586         3769      0  Well, I want to make sure we're not handing th...\n",
      "3600         3579      0    Maybe to Senator Obama it's not a lot of money.\n",
      "3783        29949      0  First of all, I got to watch in preparing for ...\n",
      "3849        34458      0  We cannot take four more years of Barack Obama...\n",
      "4293         5839      0  And I'm not going to stand for somebody saying...\n",
      "4332        32275      0  She won't say the name and President Obama won...\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    for sent in all_parts_df[\"text\"]:\n",
    "        if \"obama\" in sent.casefold():\n",
    "            print(sent)\n",
    "\n",
    "if True:\n",
    "    obama_mask = all_parts_df[\"text\"].str.contains(\"Obama\", case=False, na=False)\n",
    "    obama_df = all_parts_df.copy()[obama_mask] # Only Obama entries\n",
    "    obama_claims_df = obama_df[obama_df[\"label\"] == 1 ]\n",
    "    obama_opinions_df = obama_df[obama_df[\"label\"] == 0 ]\n",
    "\n",
    "    obama_mentions_count = len(obama_df)\n",
    "    obama_claims_count = len(obama_claims_df)\n",
    "    obama_opinions_count = len(obama_opinions_df)\n",
    "    print(f\"Total Obama mentions: {obama_mentions_count}\")\n",
    "    print(f\"Obama Claims (LABEL_1): {obama_claims_count}\")\n",
    "    print(f\"Obama Opinions (LABEL_0): {obama_opinions_count}\")\n",
    "    print(f\"Obama Claim Percentage: {(obama_claims_count / obama_mentions_count) * 100}%\")\n",
    "\n",
    "    print(\"\\nSample Obama Entries as Claims\")\n",
    "    print(\"---\" * 5 + \" Claims \" + \"---\" * 5)\n",
    "    print(obama_claims_df.head(10))\n",
    "    print(\"---\" * 5 + \" Opinions \" + \"---\" * 5)\n",
    "    print(obama_opinions_df.head(10))\n",
    "    # for i, text in enumerate(obama_claims_df[\"text\"].head(10)):\n",
    "    #     print(f\"{i}.) \\\"{text}\\\"\")\n",
    "    # print(\"\\nSample Obama Entries as Claims\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f2bdf8-3fc2-475c-ac28-8adac2cf89b9",
   "metadata": {},
   "source": [
    "## Convert to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eee1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e3cb6ed-5c27-4318-9b4c-39402fd7b19e",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "16678117-8b8a-4724-a9b9-97aca917cc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 23217\n",
      "Validation samples: 5805\n",
      "<class 'list'>\n",
      "213\n"
     ]
    }
   ],
   "source": [
    "# Split into train/validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    all_parts_df[\"text\"].tolist(), \n",
    "    all_parts_df[\"label\"].tolist(), \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_texts)}\")\n",
    "print(f\"Validation samples: {len(val_texts)}\")\n",
    "print(type(train_texts))\n",
    "print(len([x for x in train_texts if \"obama\" in x.casefold()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc2e45e-15a3-4daa-ab59-8066867ac160",
   "metadata": {},
   "source": [
    "## Step 3: Load and Setup BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c3397-3f67-484f-bec4-de0f32417a92",
   "metadata": {},
   "source": [
    "### Initialize Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef607283-a81b-4ac3-ad58-e1c5047eeee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: bert-base-uncased\n",
      "Vocabulary size: 30522\n"
     ]
    }
   ],
   "source": [
    "# Choose your BERT variant\n",
    "model_name = \"bert-base-uncased\"  # Good starting point\n",
    "# Alternatives: \"roberta-base\", \"distilbert-base-uncased\" (faster)\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Ran into tokenization issue - All tensors in a batch should be same length\n",
    "# Some were 100 and but one was 187.\n",
    "# Use padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=2  # Binary classification: claim vs opinion\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model loaded: {model_name}\")\n",
    "print(f\"Vocabulary size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443c15ed-27fe-4269-a29a-1d34df6e8117",
   "metadata": {},
   "source": [
    "### Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fcb9b832-9c74-4d30-ad9b-fd218b948b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d44de2134804b3f8ba8b8e5081ef032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23217 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860c15f1766146c3879761b55395da6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5805 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data tokenized successfully!\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'], \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=256  # Adjust based on your text length\n",
    "    )\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'text': train_texts,\n",
    "    'labels': train_labels\n",
    "})\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "    'text': val_texts,\n",
    "    'labels': val_labels\n",
    "})\n",
    "\n",
    "# Apply tokenization\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"Data tokenized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c760390-6573-4142-9d3c-4f2d6fba541f",
   "metadata": {},
   "source": [
    "## Step 4: Fine-Tune Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23d54fa-fa26-49da-886b-7953a0313307",
   "metadata": {},
   "source": [
    "We are doing **transfer learning** with **fine-tuning**. \n",
    "BERT was pre-trained to understand language - Thank you!\n",
    "We fine-tuning the model for a specific task - claim vs opinion here.\n",
    "The technique = Supervised learning with backpropagation\n",
    "\n",
    "Deep dive: BERT has millions of weights to understand language. We are adjusting these to suit our classification task. Only our final classification layer is learning from scratch. The rest of BERT is merely adapting instead of being completely retrained. \n",
    "BERT (I think) expects a \"[MASK]\" token to predict values. \n",
    "By fine-tuning, we add a layer like: `input text -> BERT Encoder -> Classification Head -> [Claim, Opinion] probabilities`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f8686b-5379-4460-aa4f-b61f01096350",
   "metadata": {},
   "source": [
    "### Define Training Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8524b-2529-4bc4-bf37-2e108cd72272",
   "metadata": {},
   "source": [
    "[transformers.TrainingArguments](https://huggingface.co/docs/transformers/v4.52.3/en/main_classes/trainer#transformers.TrainingArguments) has a lot of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45727b-67f8-4f14-85a9-0c9e27c51bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'./bert-claim-classifier_{timestamp}', # Working directory during training for logs and checkpoints.\n",
    "    num_train_epochs=3,              # Start with 3, adjust based on results\n",
    "    per_device_train_batch_size=16,  # Reduce if memory issues\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500, # gradually increase learning rate over 500 steps | prevents huge descrutive changes early on\n",
    "    weight_decay=0.01, # Very mild 1% to prevent memorizing training daata exactly. \n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    dataloader_pin_memory=False, # can help with GPU transfer speed\n",
    "    fp16=True, # mixed precision can speedup training if supported\n",
    "    dataloader_num_workers=4, # parallel data loading\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ccafc1-ad8d-4f2e-b5a2-72942d938e2d",
   "metadata": {},
   "source": [
    "### Define Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "289bdcd7-1660-4980-b12b-3d8552b3a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='weighted'\n",
    "    )\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585a5fb7-bb35-4f47-bf03-c712c233cf8e",
   "metadata": {},
   "source": [
    "### Initialize and Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801df9d2-3381-4c84-a1c1-f0369de2bc8f",
   "metadata": {},
   "source": [
    "This is the fun part we all want to do :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c1ff8-c218-4086-a2d9-aa722c602f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4356' max='4356' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4356/4356 14:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.254700</td>\n",
       "      <td>0.112086</td>\n",
       "      <td>0.963997</td>\n",
       "      <td>0.963635</td>\n",
       "      <td>0.964037</td>\n",
       "      <td>0.963997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.058669</td>\n",
       "      <td>0.986736</td>\n",
       "      <td>0.986729</td>\n",
       "      <td>0.986725</td>\n",
       "      <td>0.986736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.047583</td>\n",
       "      <td>0.991042</td>\n",
       "      <td>0.991068</td>\n",
       "      <td>0.991167</td>\n",
       "      <td>0.991042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model('./bert-claim-classifier') # Where to save model weights and config\n",
    "tokenizer.save_pretrained('./bert-claim-classifier') # for tokenizer stuff\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dadf6e7-9380-4abd-9f70-d0621a8e2890",
   "metadata": {},
   "source": [
    "## Step 5: Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a071d9c-eeda-430d-ba9c-c6899d498285",
   "metadata": {},
   "source": [
    "### Load Trained Model for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e1608-98ec-4887-ad9b-2c9673b82ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== Testing the model ===\n",
      "--------------------------------------------------\n",
      "[{'label': 'LABEL_0', 'score': 0.9985219836235046}]\n",
      "Text: 'Barack Obama was president from 2009 to 2017'\n",
      "Prediction: LABEL_0 => Opinion (confidence: 0.999)\n",
      "--------------------------------------------------\n",
      "[{'label': 'LABEL_0', 'score': 0.9998867511749268}]\n",
      "Text: 'Pizza is the most delicious food ever'\n",
      "Prediction: LABEL_0 => Opinion (confidence: 1.000)\n",
      "--------------------------------------------------\n",
      "[{'label': 'LABEL_1', 'score': 0.9998519420623779}]\n",
      "Text: 'The stock market closed at 4,500 points'\n",
      "Prediction: LABEL_1 => Factual Claim (confidence: 1.000)\n",
      "--------------------------------------------------\n",
      "[{'label': 'LABEL_0', 'score': 0.999909520149231}]\n",
      "Text: 'This movie deserves an Oscar'\n",
      "Prediction: LABEL_0 => Opinion (confidence: 1.000)\n",
      "--------------------------------------------------\n",
      "[{'label': 'LABEL_0', 'score': 0.9996640682220459}]\n",
      "Text: 'Barack Obama was born in Hawaii in 1961'\n",
      "Prediction: LABEL_0 => Opinion (confidence: 1.000)\n",
      "--------------------------------------------------\n",
      "[{'label': 'LABEL_0', 'score': 0.999607264995575}]\n",
      "Text: 'The man Barack Obama served as Senator from Illinois before becoming president.'\n",
      "Prediction: LABEL_0 => Opinion (confidence: 1.000)\n",
      "--------------------------------------------------\n",
      "[{'label': 'LABEL_0', 'score': 0.99968421459198}]\n",
      "Text: 'The man John Doe served as Senator from Illinois before becoming president.'\n",
      "Prediction: LABEL_0 => Opinion (confidence: 1.000)\n",
      "--------------------------------------------------\n",
      "[{'label': 'LABEL_0', 'score': 0.9971068501472473}]\n",
      "Text: 'Barack Obama won the Nobel Peace Prize in 2009'\n",
      "Prediction: LABEL_0 => Opinion (confidence: 0.997)\n",
      "--------------------------------------------------\n",
      "[{'label': 'LABEL_0', 'score': 0.9971133470535278}]\n",
      "Text: 'George Washington won the Nobel Peace Prize in 2009'\n",
      "Prediction: LABEL_0 => Opinion (confidence: 0.997)\n",
      "--------------------------------------------------\n",
      "[{'label': 'LABEL_0', 'score': 0.9984331727027893}]\n",
      "Text: 'Ada Lovelace wrote the first computer program way back in the 1840s!'\n",
      "Prediction: LABEL_0 => Opinion (confidence: 0.998)\n",
      "--------------------------------------------------\n",
      "[{'label': 'LABEL_0', 'score': 0.9999004602432251}]\n",
      "Text: 'My name is Kevin.'\n",
      "Prediction: LABEL_0 => Opinion (confidence: 1.000)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "# Load your fine-tuned model\n",
    "classifier = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"./bert-claim-classifier\",\n",
    "    tokenizer=\"./bert-claim-classifier\",\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"Barack Obama was president from 2009 to 2017\",  # Should be factual\n",
    "    \"Pizza is the most delicious food ever\",         # Should be opinion\n",
    "    \"The stock market closed at 4,500 points\",      # Should be factual\n",
    "    \"This movie deserves an Oscar\",                  # Should be opinion\n",
    "    \"Barack Obama was born in Hawaii in 1961\",       # More factual claims for Obama\n",
    "    \"The man Barack Obama served as Senator from Illinois before becoming president.\",\n",
    "    \"The man John Doe served as Senator from Illinois before becoming president.\",\n",
    "    \"Barack Obama won the Nobel Peace Prize in 2009\",\n",
    "    \"George Washington won the Nobel Peace Prize in 2009\",\n",
    "    \"Ada Lovelace wrote the first computer program way back in the 1840s!\",\n",
    "    \"My name is Kevin.\",\n",
    "]\n",
    "\n",
    "print(\"=== Testing the model ===\")\n",
    "print(\"-\" * 50)\n",
    "for sentence in test_sentences:\n",
    "    result = classifier(sentence)\n",
    "    label = \"Factual Claim\" if result[0]['label'] == 'LABEL_1' else \"Opinion\"\n",
    "    confidence = result[0]['score']\n",
    "    print(result)\n",
    "    print(f\"Text: '{sentence}'\")\n",
    "    print(f\"Prediction: {result[0]['label']} => {label} (confidence: {confidence:.3f})\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e1955-2f55-4616-be90-8a728c543d59",
   "metadata": {},
   "source": [
    "### Manual Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5c8f05c-239c-487e-b10f-58cda5550b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.991\n",
      "Precision: 0.991\n",
      "Recall: 0.991\n",
      "F1-score: 0.991\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(texts, true_labels):\n",
    "    \"\"\"Evaluate model on a list of texts with known labels\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for text in texts:\n",
    "        result = classifier(text)\n",
    "        # Convert to binary (0 or 1)\n",
    "        pred = 1 if result[0]['label'] == 'LABEL_1' else 0\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        true_labels, predictions, average='weighted'\n",
    "    )\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"Precision: {precision:.3f}\")\n",
    "    print(f\"Recall: {recall:.3f}\")\n",
    "    print(f\"F1-score: {f1:.3f}\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "test_texts = [\"Company revenue increased 20%\", \"I think this is wrong\"]\n",
    "test_labels = [1, 0]  # 1 = factual, 0 = opinion\n",
    "# predictions = evaluate_model(test_texts, test_labels)\n",
    "\n",
    "# Warning of using \"pipeline\" sequentially on GPU - use dataset instead.\n",
    "predictions = evaluate_model(val_texts, val_labels)\n",
    "# predictions = evaluate_model(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74403df4-62bc-42e0-9d0e-a1a0617727b7",
   "metadata": {},
   "source": [
    "## Step 6: Integration With Fact-Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33f9eb55-bc44-44fe-865f-3c273e10c4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My opponent Denver Riggleman, running mate of Corey Stewart, was caught on camera campaigning with a white supremacist', 'Now he has been exposed as a devotee of Bigfoot erotica', 'This is not what we need on Capitol Hill.']\n",
      "My opponent Denver Riggleman, running mate of Corey Stewart, was caught on camera campaigning with a white supremacist\n",
      "[{'label': 'LABEL_1', 'score': 0.9972979426383972}]\n",
      "Now he has been exposed as a devotee of Bigfoot erotica\n",
      "[{'label': 'LABEL_0', 'score': 0.9996885061264038}]\n",
      "This is not what we need on Capitol Hill.\n",
      "[{'label': 'LABEL_0', 'score': 0.9999184608459473}]\n",
      "Extracted claims: [{'text': 'My opponent Denver Riggleman, running mate of Corey Stewart, was caught on camera campaigning with a white supremacist', 'confidence': 0.9972979426383972}]\n",
      "- My opponent Denver Riggleman, running mate of Corey Stewart, was caught on camera campaigning with a white supremacist (confidence: 0.997)\n"
     ]
    }
   ],
   "source": [
    "def extract_claims_from_text(text):\n",
    "    \"\"\"\n",
    "    Extract potential factual claims from text\n",
    "    Returns list of sentences classified as factual claims\n",
    "    \"\"\"\n",
    "    # Simple sentence splitting (you might want to use spaCy for better results)\n",
    "    sentences = text.split('. ')\n",
    "    print(sentences)\n",
    "    \n",
    "    claims = []\n",
    "    for sentence in sentences:\n",
    "        if len(sentence.strip()) > 10:  # Skip very short sentences\n",
    "            print(sentence)\n",
    "            result = classifier(sentence)\n",
    "            print(result)\n",
    "            if result[0]['label'] == 'LABEL_1':  # Factual claim\n",
    "                claims.append({\n",
    "                    'text': sentence,\n",
    "                    'confidence': result[0]['score']\n",
    "                })\n",
    "    \n",
    "    return claims\n",
    "\n",
    "# Test with a Twitter example\n",
    "twitter_text = \"\"\"My opponent Denver Riggleman, running mate of Corey Stewart, was caught on camera campaigning with a white supremacist. Now he has been exposed as a devotee of Bigfoot erotica. This is not what we need on Capitol Hill.\"\"\"\n",
    "\n",
    "claims = extract_claims_from_text(twitter_text)\n",
    "print(f\"Extracted claims: {claims}\")\n",
    "for claim in claims:\n",
    "    print(f\"- {claim['text']} (confidence: {claim['confidence']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77962dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
